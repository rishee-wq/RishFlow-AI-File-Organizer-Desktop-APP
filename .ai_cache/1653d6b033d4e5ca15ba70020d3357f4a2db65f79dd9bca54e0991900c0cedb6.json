{"mtime": 1760895122.7409592, "text": "Real-time UAV-based wheat lodging detection via edge-accelerated \nimproved Mask-RT-DETR\nChengchen Pan\na , b , 1\n, Jiyuan Xie\nb , 1\n, Gan Zhang\nc\n, Tao Cheng\nb\n, Dong Han\nb\n, Qiyu Fang\nb\n,  \nShucun Ju\nc , d , *\n, Dongyan Zhang\nb , c , *\na\nNorthwest Institute of Eco-Environment and Resources, Chinese Academy of Sciences, Lanzhou 730000, China\nb\nShaanxi Key Laboratory of Agricultural Information Perception and Intelligent Service, Northwest A & F University, Yangling, Shaanxi 712100, China\nc\nNational Engineering Research Center for Argo-Ecological Big Data Analysis & Application, Anhui University, Hefei, Anhui 230039, China\nd\nAnhui Disater Earnly Warning and Agricultural Meteorological Information Center, Hefei, Anhui 230031, China\nARTICLE INFO\nKeywords:\nWheat lodging\nDeep learning\nUAV remote sensing\nMultispectral Image\nEdge computing\nABSTRACT\nTo address the challenges of slow response, low efficiency in manual field inspection, and frequent missed \ndetection of lodging areas in traditional monitoring of wheat lodging disasters, this study proposes a drone-based \nwheat lodging inspection method leveraging an improved Mask-RT-DETR model and edge computing. Consid -\nering the complex characteristics of wheat lodging in aerial images \u2014 such as diverse stem bending angles, severe \nocclusion within plant populations, and complicated background interference \u2014 three key improvements are \nintroduced to the Mask-RT-DETR model. First, a bottleneck convolutional kernel optimization module is \ndesigned, employing 1 \u00d7 1 channel compression and 3 \u00d7 3 depthwise separable convolutions to enhance the \nextraction of spectral features at stem fracture points. Second, a Cascaded Group-wise Attention (CGA) module is \nembedded into the Transformer decoder to strengthen the spatial correlation modeling of stem inclination angles \nand canopy density. By combining multi-head attention mechanisms with a cascaded group strategy, CGA re -\nduces computational load while improving feature representation. Third, the localization loss function is \nupgraded to Focal-EIoU Loss (Focal Efficient Intersection over Union Loss), which, together with a dynamic \nsample matching strategy, enhances regression accuracy of lodging bounding boxes and reduces model pa -\nrameters while preserving multi-scale feature fusion capability. A dataset is constructed using field imagery \ncollected by a drone platform equipped with high-resolution RGB and multispectral sensors. Experimental results \nshow that, compared to the original model, the improved model achieves a 6.7 percentage point increase in \nprecision and reaches a detection speed of 63.2 FPS. In cross-model comparative experiments, the proposed \nmethod outperforms Faster R-CNN, SSD, YOLO series models, and the original Mask-RT-DETR in precision (P), \nrecall (R), mean average precision (mAP), and F1-score, achieving a lodging detection accuracy of 97.2 %. To \nevaluate edge computing performance, the model is deployed on a Jetson Orin Nano embedded device. After \nacceleration with TensorRT, it achieves 96.3 % accuracy, 96.5 % recall, and a real-time detection speed of 32.0 \nFPS, satisfying the requirements for real-time, high-accuracy field monitoring. The results demonstrate that the \nimproved model maintains a lightweight architecture while significantly enhancing detection accuracy, \nproviding an effective technical solution for drone-based wheat lodging inspection that balances detection \nperformance and computational efficiency.\n1. Introduction\nAs one of the three major staple crops in the world, the stability of \nwheat yield is directly related to food security [ 41 ]. Lodging, as a major \nbiotic stress factor in wheat production, often leads to a decrease of 15 % \n\u0000 30 % in 1000-grain weight, and causes a chain reaction of mechanized \nharvesting difficulties and quality deterioration, which poses a serious \nchallenge to agricultural production [ 21 ]. Therefore, the rapid and \nThis paper is recommended by 2025 Belt and Road International Conference on Smart Agricultural Equipment Development.\n* Corresponding authors.\nE-mail addresses: jsc2678@126.com (S. Ju), zhangdy@nwafu.edu.cn (D. Zhang). \n1\nEqual contribution and first authorship: These authors contributed equally to this work and share first authorship.\nContents lists available at ScienceDirect\nSmart Agricultural Technology\njournal homepag e: www.jou rnals.elsevie r.com/smart- agricultura l-technology\nhttps://doi.org/10.1016/j.atech.2025.101509\nReceived 31 August 2025; Received in revised form 3 October 2025; Accepted 5 October 2025  \nSmart Agricultural Technology 12 (2025) 101509 \nAvailable online 6 October 2025 \n2772-3755/\u00a9 2025 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC license ( http://creativecommons.org/licenses/by- \nnc/4.0/ ). \naccurate perception of lodging disaster is the key prerequisite for the \nimplementation of precision agriculture management and the guarantee \nof stable grain production. Traditional field monitoring mainly relies on \nmanual inspection and mechanical sensors. There are technical bottle -\nnecks such as response lag, missed detection of sheltered areas and \nstrong subjectivity [ 28 ], which are difficult to meet the needs of \nlarge-scale and high-efficiency disaster assessment. Therefore, it is of \ngreat significance to construct a lodging monitoring system with high \nprecision and real-time performance for realizing dynamic perception of \ndisaster and precision agriculture management [ 1 ].\nIn recent years, UAV remote sensing technology has provided inno -\nvative solutions for crop stress monitoring due to its high spatial and \ntemporal resolution, flexible maneuverability and multi-modal percep -\ntion [ 2 ]. In agricultural applications, studies have confirmed the supe -\nrior performance of UAV platforms for crop phenotype monitoring from \ndifferent perspectives. Researchers have proposed a point-based count -\ning network SoybeanNet, which achieves high-precision counting and \npositioning of soybean pods by integrating Transformer backbone \nstructure [ 20 ]. Another study developed a method CO-YOLO for iden -\ntifying the growth pattern of Camellia oleifera fruit in two-dimensional \nimages, which can effectively detect the complex and diverse growth \npatterns of Camellia oleifera fruit in the natural environment [ 16 ]. In \naddition, based on the DeepLabv3 + model, the lightweight network \nMobileNetV2 is used as the feature extraction backbone, and the channel \nattention (CA) mechanism is introduced [ 44 ]. An optimal centerline \nextraction algorithm for field furrow area is proposed, and then a growth \nmonitoring model suitable for multiple growth periods of rapeseed \nseedlings is constructed. It is worth noting that most of the existing \nstudies focus on single-mode visible light detection. Although some \nachievements have been made in the conventional environment, there \nare still problems of insufficient detection accuracy and poor robustness \nin complex illumination conditions and crop recognition. In order to \nbreak through this bottleneck, some studies have realized the \nhigh-throughput analysis of the maturity of single bunch grapes by using \nsnapshot multispectral images, and proposed a key method that can \neffectively judge the best harvest time of fruits, which has successfully \nverified the significant advantages of multispectral data in finely \ncapturing the dynamic changes of crop physiological state [ 3 ]. The re -\nsults highlight the potential of multi-source data in phenotypic infor -\nmation acquisition, and provide a new technical path and research ideas \nfor improving the accuracy and adaptability of target detection in \nagricultural scenes through multi-modal information fusion.\nScholars at home and abroad have carried out extensive and in-depth \nresearch on crop lodging monitoring. Early work mainly relied on UAV \nor satellite remote sensing platforms, combined with visible light and \nmulti-spectral sensors, by extracting vegetation indices or constructing \ntexture features, and using statistical regression models to invert the \ndegree of lodging. For example, based on the Akaike information cri -\nterion, some studies have combined the canopy structure characteristics \nwith the binary logistic regression classification method to achieve \neffective identification of maize lodging areas and achieved good clas -\nsification results [ 7 ]. Although such methods have the potential for \nlarge-scale monitoring, they are weak in response to early and local \nlodging, and are susceptible to illumination changes, background \ninterference and vegetation coverage fluctuations. The overall accuracy \nand robustness are still limited. With the development of machine \nlearning technology, the research has gradually shifted to algorithms \nsuch as support vector machine and random forest, and combined with \nartificially designed multi-dimensional features to identify lodging. For \nexample, some studies have integrated spectral reflectance, vegetation \nindex, color space parameters and texture features, and used a random \nforest classifier based on ensemble learning to identify rice lodging \nareas, achieving a maximum overall classification accuracy of 96.1 % \n[ 19 ]. This kind of method has improved the accuracy compared with the \ntraditional statistical model, but its performance is highly dependent on \nthe quality of feature engineering. The feature extraction process is \ncumbersome and dependent on domain experience. It is difficult to fully \nexpress the complex spatial pattern of the lodging area, and the gener -\nalization ability of the model still faces challenges. In recent years, the \nwide application of convolutional neural network (CNN) has promoted \nthe technological innovation of crop lodging monitoring. With powerful \nautomatic feature learning capabilities, CNN-based semantic segmen -\ntation models (such as U-Net, DeepLabv3 + ) and object detection \nframeworks (such as YOLO series, Faster R-CNN) have gradually become \nmainstream. For example, based on the DeepLabv3 + architecture, a \nlightweight rice lodging semantic segmentation model RL-DeepLabv3 +\nwas designed, which can realize real-time lodging area segmentation in \ncomplex field environments and provide accurate lodging warning in -\nformation for unmanned rice harvesters [ 33 ]. In addition, another study \nproposed a multi-modal deep learning model that combines \nself-supervised pre-training and fine-tuning stage comparative learning. \nCombined with multi-source data, the yield prediction and lodging \ndiscrimination of soybean germplasm resources were carried out. The \nresults showed that the feature correlation between different varieties \nwas significantly reduced (the mean value of Pearson correlation coef -\nficient decreased from 0.62 to 0.27), indicating that the model had \nstronger feature decoupling ability and generalization performance \n[ 49 ]. In summary, crop lodging monitoring is evolving from the tradi -\ntional method relying on artificial features and shallow models to the \nintelligent direction driven by deep learning and multi-modal fusion, \nwhich provides a solid technical support for accurate, efficient and \nall-weather field monitoring.\nWith the continuous breakthrough of visual Transformer technology, \nthe object detection method based on DETR architecture has gradually \nshown significant advantages in the field of crop phenotype analysis due \nto its excellent global context modeling ability and end-to-end detection \nparadigm. Some studies combined RepVGG module and MPDIoU loss \nfunction in cucumber detection task, which increased mAP50 by 3.2 \npercentage points and significantly improved the positioning accuracy \nand convergence stability of the model [ 31 ]. In addition, by using Effi -\ncientViT as the backbone network and designing an adaptive detail \nfusion module, the efficient reasoning speed of 41.2 FPS is realized in \ncherry tomato detection, which takes into account both accuracy and \nreal-time performance [ 47 ]. The current research has fully verified the \napplicability and superiority of the RT-DETR architecture in the detec -\ntion of multiple crop targets, including typical crops such as tomatoes \n[ 48 ], citrus [ 13 ], and apples [ 11 ]. By introducing a dynamic label \nallocation mechanism, the architecture achieves real-time reasoning \nperformance of 10 \u2013 30 FPS while ensuring detection accuracy, and meets \nthe needs of high-frequency and large-scale monitoring in agricultural \nscenarios. Furthermore, compared with the traditional bounding \nbox-only detection model, Mask-RT-DETR can output pixel-level \ninstance segmentation masks, and has stronger ability to depict lod -\nging areas with irregular shapes, blurred boundaries or mutual occlu -\nsion. It can provide richer morphological information, such as lodging \narea, tilt direction and canopy continuity, which is significantly better \nthan the rough expression of rectangular boxes. The model inherits the \nadvantages of the DETR series in long-distance dependence modeling. At \nthe same time, by optimizing the training strategy and network struc -\nture, it effectively alleviates the problems of slow convergence speed \nand large computational overhead of the original DETR, and achieves \nfast, stable and high-precision instance segmentation performance. In \nview of its comprehensive advantages in accuracy, speed and semantic \nexpression ability, especially in line with the dual needs of UAV platform \nfor real-time and fine-grained recognition in complex field environ -\nments, this study selected Mask-RT-DETR as the baseline model, aiming \nto build a set of high-precision and real-time detection system suitable \nfor wheat lodging monitoring, and provide reliable technical support for \nsubsequent field intelligent management.\nHowever, although advanced models such as Mask-RT-DETR have \nperformed well in general-purpose object detection and segmentation \ntasks, their architecture design is mainly oriented to general-purpose \nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n2 \nscenarios, without fully considering the complexity of the agricultural \nfield environment, nor customized optimization for the morphological \ncharacteristics unique to wheat lodging. When it is applied to the spe -\ncific task of wheat lodging detection, it still faces three key challenges: \nFirst, the lodging morphology of wheat is highly diverse, and the stem \nshows a continuous bending angle from slight tilt to full adhesion, \nresulting in significant non-rigid deformation and spatial distribution \ndiscreteness in the visual representation of the lodging area, which is \ndifficult to be effectively modeled by the fixed-mode detection head. \nSecondly, under the condition of high density planting, the mutual oc -\nclusion between plants is serious, resulting in the lack of local infor -\nmation or contour fracture in the lodging area, which is easy to cause \nmissed detection, especially for the recognition ability of mild lodging \nand local inclined areas is limited. Thirdly, the field background is \ncomplex and changeable, and the interference factors such as soil \nshadow, residual straw, and weed coverage are highly similar to the \nlodging area in color and texture, which makes the model easy to \nmisjudge the non-lodging area as a positive target, seriously affecting \nthe specificity and robustness of the detection. In addition, the actual \nlanding of the model also faces the engineering bottleneck of lightweight \nand edge deployment. Although the high-performance model can ach -\nieve accurate segmentation on the server side, its large number of pa -\nrameters and high computational overhead make it difficult to meet the \nUAV platform \u2019 s demand for low-latency, low-power real-time \nreasoning. How to realize model compression and acceleration under \nthe premise of maintaining high precision and promote the \u2019 end-edge \u2019 \ncollaborative deployment architecture is the key link to realize real-time \nfield monitoring. In view of the above problems, the existing research \nprovides a useful reference for lightweight design. For example, by \ncombining the reparameterization structure of RepVGG and the light -\nweight attention mechanism of MobileViT, some studies have success -\nfully compressed the parameters of buckwheat segmentation model to \n9.01 \u00d7 10\n6\n, taking into account both expression ability and reasoning \nefficiency [ 17 ]. Another study introduced the Inverted Residual Mobile \nBlock in wood defect detection, which significantly reduced the \ncomputational complexity by 57 % while maintaining the detection \nstability [ 10 ]. These lightweight strategies provide an important tech -\nnical path reference for this study to optimize the network structure, \nbalance accuracy and efficiency. In summary, in order to meet the actual \nneeds of wheat lodging detection, it is urgent to enhance the structure of \nlodging morphological diversity, occlusion severity and background \ninterference complexity based on the Mask-RT-DETR baseline model. \nCombined with efficient lightweight design, a special detection frame -\nwork with high precision, strong robustness and real-time reasoning \nability is constructed to support the efficient autonomous inspection of \nUAV platform in complex field environment.\nTo address these challenges, this study proposes an improved Mask- \nRT-DETR-based architecture incorporating three core optimization \nstrategies: (1) A bottleneck-style convolutional kernel optimization \nmodule is designed to enhance spectral-spatial feature extraction for \nstem break points and lodging textures; (2) A cascaded grouped atten -\ntion module is constructed to efficiently strengthen long-range spatial \ndependencies and local correlation modeling through grouped compu -\ntation and cascading mechanisms, effectively mitigating occlusion is -\nsues; (3) The Focal-EIoU loss function is introduced to focus on hard \nsample optimization based on EIoU, improving bounding box regression \naccuracy for lodging regions with complex morphologies. Finally, \nleveraging a multispectral-visible light fused dataset developed in this \nstudy, the advantages of multi-source information are fully exploited, \nand the model \u2019 s edge computing performance is systematically evalu -\nated on the Jetson Orin Nano embedded platform. Through compre -\nhensive optimization, the proposed model achieves a balanced trade-off \nbetween model size ( < 20 M parameters) and inference speed ( > 30 FPS), \noffering an integrated solution for UAV-based wheat lodging inspection \nthat simultaneously ensures detection accuracy, robustness, and \ncomputational efficiency. This work provides a reliable technical \npathway toward intelligent disaster monitoring in grain production.\n2. Materials and data\n2.1. Introduction of the study area\nThe study area is located in the Baihu wheat comprehensive exper -\nimental station in Lujiang County, Anhui Province (geographical co -\nordinates: 31\n\u25e6\n13 \u2032 N, 117\n\u25e6\n27 \u2032 E). In the experimental field, Yangmai 25 \nwheat variety (plant height 82 \u00b1 3 cm, stem flexural strength 2.1 N/ \nmm\n2\n) was planted by traditional sowing method, and the planting \ndensity was 180 plants /m\n2\n. Based on the data provided by the Anhui \nAgricultural Meteorological Center, a total of 11 lodging events caused \nby heavy rainfall were recorded in the study area from 2019 to 2024. \nAmong them, seven events occurred in early May (specific dates: May \n16,2019, May 3,2020, May 12,2021, May 5,2022, May 4,2023, May \n7,2024, May 15,2024). Field observations show that the tilt angle of the \ncrop canopy in the lodging area is generally > 60\n\u25e6\n, up to 78\n\u25e6\nIn this \nstudy, a contiguous wheat field with an area of 182 hectares in the \nexperimental station was used as the core experimental area (the data \ncoverage period was 2019 \u2013 2024). The lodging disaster loss data and \nsupporting meteorological records in this area are complete. The \ngeographical location and data collection of the study area can be seen \nin Fig.1 .\n2.2. UAV data acquisition\nIn this study, DJI Mavic 3 M UAV platform equipped with visible \nlight and multi-spectral dual-mode imaging system was used for data \nacquisition. The system integrates a 20-megapixel visible light camera \nand a four-band multispectral sensor (covering green, red, red and near- \ninfrared bands). Among them, the resolution of each single band of the \nmulti-spectral sensor is 5 million pixels. The integrated platform can \nsimultaneously obtain high-resolution visible light images and multi- \nspectral information, and provide spatial data sources with high- \nresolution and multi-spectral dimensions for subsequent analysis. Aim -\ning at the characteristics of large stem inclination angle and high canopy \noverlap in wheat lodging area, the flight height is set to 20 m This height \nnot only ensures the complete coverage of the lodging shape, but also \neffectively avoids the blade airflow disturbance. The data acquisition \nprocess adopts the automatic focusing mode to accurately lock the \nbroken point of the stem base and the inclination angle of the canopy in \nthe lodging area. All image data is temporarily stored in the UAV \u2019 s built- \nin 256 GB storage space, and then transmitted to the server for \npreprocessing.\nDuring the six consecutive years from 2019 to 2024, the Baihu \nExperimental Station carried out wheat lodging monitoring research. In \norder to ensure the quality of data, this study usually collects data from \n12: 00 to 16: 00 with stable daily light and dry dew within 24 h after the \noccurrence of lodging disaster. During this period, the inclination angle \nof lodging stem is stable and the influence of dew is minimal, which is \nconducive to the model to accurately capture the typical lodging \nmorphological characteristics [ 12 ]. The data collection was concen -\ntrated from the milk stage to the mature stage of wheat (May 10 to June \n15). During this period, seven special aerial survey flights were orga -\nnized for strong wind and heavy rainfall (the main cause of lodging) [ 8 ]. \nThe system collected sample data with different degrees of lodging, such \nas slight tilt, complete lodging and stem breakage. The collected data are \ngenerated by Metashape 2.1.0 software to generate a digital orthophoto \nmap of the 129.36 hectare test area, and the 640 pixel sliding window is \nused to cut the stitched image. The pixel size of the cut image is 640 \u00d7\n640. Under drone aerial imagery, lodged wheat areas exhibit charac -\nteristic morphological and spectral features: the stem inclination angle is \nlarge (the angle between the canopy of lodged plants and the ground is \ngenerally < 60\n\u25e6\n, and in severe cases, approaches ground level); canopy \nstructure is disordered (lodged areas appear as irregular clumps or \nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n3 \nbands, with interruptions in canopy continuity); distinct stem breakage \npoints are visible (in high-resolution visible-light images, fractures or \nbending marks can be observed at the base or middle of stems); and \nmultispectral responses are anomalous (in the near-infrared and \nred-edge bands, lodged areas exhibit pronounced spectral anomalies due \nto impaired photosynthesis and overlapping or self-shading of leaves). \nAccording to the field survey results, the agronomic experts marked the \nlodging area, and finally obtained 41,685 valid images. Among them, \nthere are 8337 visible light images and 33,348 multi-spectral images. \nThese high-quality multi-modal data will be used for subsequent model \ntraining and optimization.\n2.3. Dataset producing\nIn this study, a multimodal data set was constructed based on 41,685 \nvalid original images after acquisition and segmentation. In view of the \nsignificant spectral response difference of stem morphological charac -\nteristics in wheat lodging area in multi-spectral bands, multi-spectral \nimages are used in the training stage, so that the target detection \nmodel can learn more abundant information of the target area in the \nsame time and space [ 22 ]. In the test phase, visible light images are used \nto adapt to the computing power limitations of edge devices and better \nmatch the actual application scenarios. The 8337 visible light images \nwere selected separately as Dataset1 and divided into training set, \nvalidation set and test set at a ratio of 7: 2: 1. In Dataset2, 33,348 \nmultispectral images are all used as training sets, and the visible light \nimages still maintain a 7: 2: 1 partition ratio. Dataset3 expands all 41, \n685 original images to 104,213 after data enhancement (mirror flip, \nrotation, brightness change, etc.), and the data partitioning method is \nconsistent with Dataset2. The distribution of multispectral image (Msi) \nand visible image (Vi) of each dataset is shown in Table 1 .\nTo ensure consistency and practicality of the annotation results, this \nstudy employs the LabelImg tool to treat continuous, extensive lodged \nareas as single overall instances, annotating their minimum bounding \npolygons to precisely match the actual extent of lodging. During anno -\ntation, all clearly inclined or fully lodged plants are included, covering \nstem fracture points and the resulting canopy collapse regions, while \nexcluding temporary bends caused by brief wind gusts without physical \ndamage. The annotation work was collaboratively conducted by three \nresearchers with backgrounds in agricultural remote sensing. Each \nimage was cross-validated by at least two annotators, and any discrep -\nancies were resolved by a third expert in agronomy.\n3. Methodology\nMask-RT-DETR achieves dynamic label allocation and lightweight \ndecoding through an end-to-end Transformer architecture [ 42 ]. Its core \nadvantage lies in the sample allocation mechanism, that is, the weight of \npositive and negative samples is dynamically adjusted according to the \ntarget characteristics in the training process, which solves the problem \nof sample redundancy caused by the scale change of lodging area in \ntraditional detection [ 15 ]. At the same time, the lightweight Trans -\nformer decoder uses a deformable attention mechanism to reduce the \ncomputational complexity from O (n\n2\n) to O (n) while maintaining the \nglobal feature modeling ability, which significantly improves the \ndetection efficiency of the lodging area [ 38 ].\nIn this study, the wheat lodging target in the multi-spectral image of \nFig. 1. Research area and acquisition of UAV remote sensing images.\nTable 1 \nDistribution of Msi and Vi across three datasets.\nDatasets Msi Vi Total\nDataset1 0 8337 8337\nDataset2 33,348 8337 41,685\nDataset3 83,370 20,843 104,213\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n4 \nUAV showed the characteristics of spectral anomaly at the stem break, \nserious group occlusion and spectral interference between background \nsoil and weeds. The Mask-RT-DETR model was improved in multiple \ndimensions: the bottleneck convolution kernel optimization module was \ndesigned, and the \u2019 compression-spectral sensing-expansion \u2019 three-stage \nresidual structure was constructed in the feature extraction path. The 1 \n\u00d7 1 convolution compression input channel was used to eliminate the \nredundancy of multi-spectral bands, and the 3 \u00d7 3 depth separable \nconvolution was used to focus on the spectral anomaly characteristics of \nthe stem break point and strengthen the perception of key areas. The \ncascade group self-attention mechanism is designed to embed the \nTransformer decoder. The feature dimension of the multi-head attention \nmechanism is divided into three functional modules: stem direction, \nspectral anomaly and canopy continuity. The modeling accuracy of the \nspatial distribution law of the lodging area is improved by cascade \ncalculation. Finally, the Focal-EIoU loss function is used to replace the \noriginal GIOU Loss.Through the minimum closure region calculation \nand dynamic weight distribution strategy, the regression ability of the \nlodging bounding box is strengthened, and the parameter quantity is \ncompressed while retaining the multi-scale feature fusion ability, which \nadapts to the computing power limit of the Jetson Orin Nano edge de -\nvice.The improved model structure is shown in Fig.2 .It significantly \nimproves the detection robustness of wheat lodging area under complex \nbackground through multi-spectral feature enhancement and cascade \nattention mechanism optimization.\n3.1. Construction of bottleneck convolution kernel\nIn the wheat lodging detection from the perspective of UAV, the \ndouble 3 \u00d7 3 convolution stacking structure of the traditional HGBlock \nmodule has the problems of channel redundancy and small target \nfeature weakening [ 35 ]. Due to the spectral interference between the \nstalk breaking point in the lodging area and the background soil and \nweeds, the full connection characteristics of the high-dimensional \nfeature channel easily lead to the explosion of the parameter space, \nand the shallow texture features are easily diluted in the cross-stage \ntransmission [ 43 ]. To this end, this study proposes a three-stage \nbottleneck mechanism of \u2019 compression-spectral sensing-expansion \u2019 , \nwhich dynamically regulates channel dimensions through 1 \u00d7 1 \nconvolution to optimize the utilization efficiency of multi-spectral \nfeatures.\nSpecifically, as shown in Fig. 3 , in the improved residual module, the \nfirst layer of 1 \u00d7 1 convolution compresses the input channel to the \noriginal 1 / 4 (e.g., 1024 \u2192 256), eliminating the redundant response of \nthe spectrum; then, the 3 \u00d7 3 depth separable convolution was used to \nfocus the texture fracture features of the stem breaking point, and the \nsensitive features of spectral difference were retained by channel \ngrouping calculation. The last layer 1 \u00d7 1 convolution reconstructs the \nchannel dimension (256 \u2192 1024) to restore the group occlusion \ndiscrimination ability of the lodging area. Taking the feature processing \nof the near-infrared band as an example, the traditional double 3 \u00d7 3 \nconvolution parameter P is shown in Eq. (1) : \nP = C\nin\n\u00d7 C\nout\n\u00d7 3\n2\n(1) \nThe improved bottleneck structure compresses the parameters \nthrough hierarchical optimization. The calculation method is shown in \nEq. (2) : \nP = C\nin\n\u00d7\nC\nmid\n4\n\u00d7 1 +\nC\nmid\n4\n\u00d7\nC\nmid\n4\n\u00d7 3\n2\n+\nC\nmid\n4\n\u00d7 C\nout\n\u00d7 3\n2\n(2) \nIn the above lightweight combination design, the bottleneck residual \nstructure reduces the number of parameters to 62.3 % of the original \nstructure while maintaining the sensitive characteristics of the breaking \npoint in the near-infrared band, which can significantly improve the \nreasoning efficiency of the UAV edge equipment.\n3.2. Neck network based on cascaded grouping attention\nIn Mask-RT-DETR \u2019 s Transformer decoder, the self-attention mech -\nanism improves the spatial relationship modeling ability of the lodging \narea through global feature interaction [ 39 ], but its Multi-head Atten -\ntion (MHA) module has computational redundancy when processing \nmulti-spectral lodging images taken by UAV aerial photography. When \nthe size of the input feature map increases, the matrix multiplication of \nthe query, key, and value of the MHA module increases significantly. \nEspecially when capturing the continuous distribution characteristics of \nlodging stems and the cross-modal correlation between multi-spectral \nbands, the traditional MHA needs to maintain the feature dimensions \nof all heads at the same time, which makes it difficult for memory usage \nand computing cost to adapt to the edge deployment requirements [ 5 ]. \nIn order to solve this problem, this paper introduces the Cascaded \nGroup-wise Attention (CGA) mechanism in the decoder to improve the \nMHA module.\nThe improved CGA module structure is shown in Fig. 4 . The core idea \nis to introduce a cascade grouping strategy in the feature dimension \ndivision stage of the multi-head attention mechanism [ 24 ]. Different \nFig. 2. A lodging detection model based on the improved Mask-RT-DETR.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n5 \nfrom the standard MHA, which processes all x heads in parallel, CGA \nfirst divides the input feature map into g non-overlapping groups (this \nstudy sets g = 3, corresponding to the stem direction group, the spectral \nanomaly group, and the canopy continuity group), and each group \ncontains partial channel dimensions of the original feature map. The \nCGA module first divides the complete features by Eq. (3) : \n\u0303\nX\nij\n= Attention\n(\nX\nij\nW\nQ\nij\n, X\nij\nW\nK\nij\n, X\nij\nW\nV\nij\n)\n(3) \nIn the formula, \n\u0303\nX\nij \nis the output feature of the i th input feature \nprocessed by the j th attention head, Attention is the attention operation, \nX\nij \nis the j th slice of the input feature X\ni\n, W\nQ\nij\n, W\nK\nij\n, W\nV\nij \nare the query \nfeatures, value features and related features obtained by different layers \nof input feature mapping. In the calculation process, the output feature \n\u0303\nX\nij \nof the jth group is not only generated by the input feature X\nij \nof the \ncurrent group through the attention operation, but also the output in -\nformation \n\u0303\nX\ni ( j \u0000 1 )\nof the previous j-1 group is fused. The calculation \nprocess is as shown in (4) and (5) : \n\u0303\nX\ni + 1\n= Concat\n\u0000\n\u0303\nX\nij\n)\nj = 1 : x\nW\nP\ni\n(4) \nX\n\u02b9\nij\n= X\nij\n+\n\u0303\nX\ni ( j \u0000 1 )\n(5) \nIn the formula, \n\u0303\nX\ni + 1 \nis the result of splicing projection of all the \nfeatures processed by the attention head, Concat is the splicing opera -\ntion, b is the total number of attention heads, W\nP\ni \nis the projection of the \noutput features after splicing, X\n\u02b9\nij \nis the sum of the input slice X\nij \nof the \ncurrent head and the output of the previous head \n\u0303\nX\ni ( j \u0000 1 )\n, which follows i \n< j \u2264 h .\nThe design realizes feature multiplexing between attention heads \nthrough cascade calculation: the stem direction group preferentially \nextracts the tilt angle feature of the lodging area, and its output feature is \ntransmitted to the spectral anomaly group for sensing the spectral dis -\ntribution difference. Finally, the canopy continuity group combines the \nfirst two sets of features to strengthen the modeling of the group oc -\nclusion relationship in the lodging area [ 34 ]. Through the grouping \ncascade strategy, the CGA module not only reduces redundant calcula -\ntions, but also enables each group of attention heads to focus on specific \nfeature dimensions and reuse the output information of the pre-order \ngroup. Finally, while maintaining the diversity of features, the mem -\nory footprint of the decoder is reduced. The improved decoder structure \nis named CGA-Transformer and completely replaces the original \nmodule.\n3.3. Optimization of loss function\nThe original regression loss of the Mask-RT-DETR model uses GIOU \nLoss to calculate the matching error between the prediction box and the \nreal box [ 42 ]. The loss function improves the detection accuracy by \ndynamically optimizing the weight of positive and negative samples. \nHowever, there are two limitations in dealing with the wheat lodging \narea of UAV aerial photography. First, when the intersection over union \n(IoU) of the minimum circumscribed rectangle of the lodging stem and \nthe prediction frame approaches zero, the loss value cannot reflect the \ndistance difference between the two [ 27 ], resulting in unstable gradient \nupdate at the initial stage of training. Second, the imbalance of the \nspatial distribution of lodging samples is not considered-the lodging area \nof the population often presents a continuous zonal distribution, and the \nproportion of lodging samples per plant is insufficient. This imbalance in \nthe proportion of samples easily makes the model biased towards the \nconvergence of most samples [ 4 ].\nIn response to the above problems, this paper introduces the Focal- \nEIoU loss function in the decoder, and its improved logic is shown in \nFig. 5 . Focal-EIoU optimizes bounding box regression through three- \nstage modeling: Firstly, based on the minimum closure region calcula -\ntion of EIoU Loss ( Eq. (3) ), the width difference ( \u0394 w ) and height dif -\nference ( \u0394 h ) between the predicted frame and the real frame are taken \nas independent optimization objectives, so that the model can decouple \nthe breaking point position ( \u0394 w corresponds to the stem base damage) \nand the tilt length ( \u0394 h corresponds to the canopy coverage) of the lod -\nging stem. Secondly, the Focal Loss \u2019 s sample weight attenuation \nmechanism ( formula (4) ) is embedded in the IoU loss, and the gradient \ncontribution of simple samples (normal area of high IoU) and difficult \nsamples (lodging area of low IoU) is controlled by adjusting the \nparameter \u03b3 , so that the model training process is more focused on the \nregression optimization of the lodging bounding box. Finally, the \nEuclidean distance between the center point of the prediction box and \nthe real box is constrained by the distance loss ( Eq. (5) ) to enhance the \nmodeling ability of the spatial continuity of the lodging area.\nThe IOU loss L\nIOU \nfor measuring the similarity between two arbitrary \nshapes (volumes) is shown in Formula (6) . \nFig. 3. Bottleneck residual structure diagram.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n6 \nL\nIOU\n= 1 \u0000\n| A \u2229 B |\n| A \u222a B |\n(6) \nL\nIOU \nhas good properties such as non-negativity, symmetry, triangle \ninequality and scale insensitivity, and has been proved to be a metric. \nHowever, it has two main drawbacks: if the two boxes do not have any \nintersection, IOU will always be zero, which cannot correctly reflect the \ncloseness between the two boxes. And the convergence speed of IOU \nLoss is slow. In order to solve the above problems, this study introduces a \nmore effective version of IOU loss, namely EIOU loss L\nEIOU\n, which is \ndefined as Eq. (7) . \nL\nEIOU\n= L\nIOU\n+ L\ndis\n+ L\nasp\n= 1 \u0000 IOU +\n\u03c1\n2\n\u0000\nb , b\ngt\n)\n( w\nc\n)\n2\n+ ( h\nc\n)\n2\n+\n\u03c1\n2\n( w , w\ngt\n)\n( w\nc\n)\n2\n+\n\u03c1\n2\n\u0000\nh , h\ngt\n)\n( h\nc\n)\n2\n(7) \nWhere b denotes the center coordinates of the predicted bounding \nbox; b\ngt \ndenotes the center coordinates of the ground truth bounding \nbox; \u03c1 ( \u2022 ) represents the Euclidean distance function; indicates the \nspatial distance between the centers of the predicted and ground truth \nboxes; w and h are the width and height of the predicted box, respec -\ntively; w\ngt \nand h\ngt \nare the width and height of the ground truth box, \nFig. 4. Cascaded group attention structure.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n7 \nrespectively; w\nc \nand h\nc \nare the width and height of the smallest enclosing \nbox that covers both the predicted and ground truth boxes. The loss \nfunction is divided into three parts: IOU loss, distance loss and azimuth \nloss. EIOU Loss minimizes the difference between the width and height \nof the target box and the Anchor directly, resulting in faster convergence \nspeed and better positioning results.\nIn the actual model training process, there is a problem of unbal -\nanced training examples, that is, due to the sparsity of the target in the \nimage, the number of high-quality examples with small regression error \nis much less than that of low-quality examples [ 46 ]. Therefore, it is \ncrucial to focus the regression process on high-quality anchor frames. \nThis study introduces a new loss function, namely Focal-EIOU loss L\nFo -\ncal-EIOU\n, as shown in formula (8) . \nL\nFocal \u0000 EIOU\n= IOU\n\u03b3\nL\nEIOU\n(8) \nIn the formula, \u03b3 is a parameter to control the degree of abnormal \nvalue suppression. After parameter optimization in the training process, \nit is finally determined to be 0.5. This design allows the model to pref -\nerentially correct the missing lodging area during the training process, \nwhile suppressing the false detection of background weeds and other \ninterferences. The final improved loss function provides a more robust \nbounding box regression strategy for UAV lodging detection through \nthree-stage optimization of minimum closure region calculation, diffi -\ncult sample focusing and spatial continuity constraint.\n3.4. Inspection system based on edge computing\nIn order to solve the problems of traditional wheat lodging detection \nrelying on manual inspection and lack of real-time field diagnosis \nequipment, this study designed an embedded system for lodging \ndetection based on drones. The hardware of the device is composed of \nairborne computing unit, power management system and wireless \ntransmission module. The airborne computing unit uses NVIDIA Jetson \nOrin Nano embedded device, which has 1024 NVIDIA CUDA cores and \n32 Tensor cores. At the same time, it is also equipped with a 6-core Arm \nCortex-A78AE 64-bit CPU, memory of 8GB 128-bit LPDDR5, with a \nbandwidth of 68GB / s, which can provide excellent computing per -\nformance. Its power consumption is only 10W-25 W, which is suitable \nfor UAV endurance requirements. The power management system con -\nsists of main battery, DC-DC voltage regulator module and intelligent \npower-off protection circuit, which ensures the stable power supply of \nthe calculation unit under strong wind disturbance. The wireless trans -\nmission module uses a 5.8 GHz image transmission system to transmit \nthe detection results back to the ground station software in real time. \nThe detection system is shown in Fig.6 .\nThe working process of the device is shown in Fig.6 .Firstly, the UAV \npower supply is started, and the angle of the pan-tilt is controlled to the \nlodging detection mode through the ground station software. Then the \ndrone flew over the target wheat field and hovered. The acquisition \nmodule automatically adjusted the exposure parameters (ISO 100 \u2013 800 \nadaptive) to match the illumination difference. The collected multi- \nspectral images are invoked by the edge computing unit to improve \nthe lightweight lodging detection model for localized reasoning, First, \nautomatic exposure correction is applied to the original images to sta -\nbilize brightness. Second, local cropping is performed to adapt the im -\nages to the model \u2019 s input size and enhance the detection performance of \nsmall targets. Third, images are pixel-normalized to the [0,1] range and \nchannel-wise standardized according to ImageNet statistics. Finally, \nduring testing and deployment, single-modal visible light images are \nused as model inputs to detect lodged wheat areas. Then the lodging area \nbounding box and classification confidence output by the model are sent \nto the ground station through the wireless transmission module. Finally, \nthe ground station software displays the test results. Through the \ncollaborative design of airborne computing unit and ground station, the \nportability and rapid deployment ability of UAV are highlighted, and the \nreal-time detection system of UAV suitable for wheat lodging disaster \ndiagnosis is constructed.\n3.5. Environment setting and evaluation index\nThis study uses precision, average precision (AP), P (Precision), \nrecall (R), detection frame rate (FPS), etc.as the evaluation indicators of \nthe model. Among them, the accuracy rate and recall rate are contra -\ndictory indicators, so AP is selected to comprehensively consider the \ntwo. The larger the AP value, the better the comprehensive performance \nof the algorithm. Among them, AP @ 0.5 is the average detection ac -\ncuracy when the IoU threshold is equal to 0.5, and AP @ 0.5: 0.95 \nrepresents the average detection accuracy of the IoU threshold with a \nstep size of 0.05. FPS is used to measure the detection speed of the al -\ngorithm. The calculation method of each index is shown in Eq. (9) - Eq. \n(12) . \nP =\nTP\nTP + FP\n(9) \nR =\nTP\nTP + FN\n(10) \nFig. 5. The structure of the Focal-EIoU loss function.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n8 \nAP =\n\u222b\n1\n0\np ( r ) dr (11) \nF 1 = 2 \u00d7\nP \u00d7 R\nP + R\n(12) \nIn the formula P represents the proportion of the correct part of the \nmodel prediction to the overall prediction result, specifically, the \nnumber of lodging areas correctly identified by the model accounts for \nthe percentage of the total number identified by the model. R refers to \nthe proportion of the number of correctly predicted positive samples to \nthe actual total positive samples, that is, the percentage of the number of \nlodging areas correctly predicted by the model to all the total. TP is the \nnumber of actual sample objects that are correctly classified in the data \nset; fP is the number of sample objects misdetected by the detected \nmodel; fN is the number of samples missed in the detection model.\nIn order to ensure the fairness of the experiment, all models are \ntrained in the same hardware environment. The CPU used in the test \nplatform is AMD Ryzen Threadripper 7960X, the GPU is NVIDIA \nGeFarce RTX 5090, the CUDA version is 11.3, and the deep learning \nframework is Pytorch 2.3.1, which is performed under the Windows11 \noperating system.\nIn this study, the model parameters pre-trained by the COCO dataset \nwere used as the initial weight of training. The model training was set to \n200 rounds and the batchsize was set to 16. In order to ensure the \nfairness of the ablation test and the comparison test, the same hyper -\nparameters are used in the subsequent ablation test. The comparative \nexperiments of different models use their default hyper-parameter set -\ntings instead of any hyper-parameter optimization through the results of \nthe validation set.\n4. Results\n4.1. Ablation experiment\nIn order to verify the effectiveness of the improved strategies \n(bottleneck convolution kernel, cascade group self-attention, loss func -\ntion optimization) proposed in this study in wheat lodging detection, a \nstep-by-step embedded ablation experiment was designed. Through \nmodular removal testing on Dataset3, the impact of each improved \ncomponent on detection accuracy, computational efficiency, and edge \ndeployment suitability is systematically evaluated.\nTable 2 shows the performance comparison under different \nimprovement combinations. The ablation experimental system verified \nthe contribution of each improved module to the detection performance \nof wheat lodging. The benchmark model reaches mAP @ 0.5 of 0.851 on \nDataset3, but there is a problem of 42.7 FPS inference speed and 32.8 M \nparameter limit deployment. After introducing the bottleneck convolu -\ntion module BCKM, the number of model parameters is compressed by \n52 % to 15.6 M, the inference speed is increased by 62.8 % to 69.5 FPS, \nand the accuracy and recall rate are increased by 1.8 percentage points \nand 3.5 percentage points respectively. After superimposing the \ncascaded grouping attention module CGA, the multi-scale feature fusion \nincreases mAP @ 0.5 by 10.7 percentage points to 0.944, and the recall \nrate by 8.3 percentage points to 94.2 %. Finally, the Focal-EIoU loss \nfunction is introduced to optimize the bounding box regression. While \nalleviating the class imbalance, mAP @ 0.5 and AP @ 0.5: 0.95 are \nincreased to 0.958 and 0.796 respectively, forming the optimal balance \nbetween accuracy and efficiency.This experiment confirms that the \nBCKM module achieves a leap in computational efficiency, the CGA \nmodule enhances the ability of fine-grained feature extraction, and the \nFocal-EIoU loss function significantly improves the robustness of small \ntarget detection. The three collaboratively provide a high-precision so -\nlution for real-time lodging detection in complex agricultural scenarios.\n4.2. Performance comparison on different data sets\nIn order to verify the generalization ability of the improved model in \nvisible light (Dataset1), multispectral-visible light fusion (Dataset2) and \ndata augmentation set (Dataset3), the original Mask-RT-DETR and the \nimproved model were compared across data sets. Table 3 shows the \ndetection accuracy, recall rate and inference speed of the model under \nFig. 6. Edge computing inspection UAV detection system.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n9 \ndifferent data distributions.\nExperiments show that the improved model shows significant per -\nformance improvement in cross-dataset testing. On the visible light data \nset (Dataset1), the accuracy of the improved model reaches 69.4 %, \nwhich is 1.5 percentage points higher than the basic model, the recall \nrate is increased by 1.7 percentage points to 64.9 %, and the average \naccuracy AP @ 0.5 is increased by 1.1 % to 0.632. On the multi-spectral \nfusion dataset (Dataset2), the model accuracy increased by 1.7 per -\ncentage points to 81.2 %, and the recall rate increased by 1.7 percentage \npoints to 76.7 %. The improvement is most significant on the enhanced \ndata set (Dataset3): the accuracy is increased by 6.1 percentage points to \n97.2 %, the recall rate is jumped by 10.8 percentage points to 96.7 %, \nand AP @ 0.5 is greatly increased by 10.7 percentage points to 0.958. \nThe inference speed is improved synchronously, and the inference speed \nof the three sets of data sets is increased by 52.2 %, 50.4 % and 48.0 % \nrespectively, and the collaborative optimization of accuracy and effi -\nciency is realized. Combined with the results in Table 3 , the improved \nmodel has the best detection effect in data set 3, and the model trained \nby data set 3 is selected as the lodging detection model.\n4.3. Performance comparison of different benchmark models\nIn order to verify the performance advantages of the improved RT- \nDETR model in wheat lodging detection task, Faster R-CNN, SSD, \nYOLO series models and original Mask-RT-DETR were used as baseline \nmodels for horizontal comparison. Table 4 shows the precision, recall, \nmAP and detection speed (FPS) of each model on Dataset3.\nExperiments show that Mask-RT-DETR has significant advantages in \naccuracy, recall and inference speed on the Dataset3 dataset. Specif -\nically, its accuracy (91.1 %) is 24.6 percentage points higher than that of \nFaster R-CNN (66.5 %) and 8.2 percentage points higher than that of \nYOLOv8n (82.9 %). The inference speed is 42.7 FPS, which is 157 % \nhigher than that of Faster R-CNN (16.6 FPS). On the AP @ 0.5 index, RT- \nDETR (0.851) was 31.7 % higher than SSD (0.647). It is worth noting \nthat the YOLO series models achieve a high detection frame rate \ncompared to Mask-RT-DETR, but its accuracy and recall rate are rela -\ntively low, indicating that the model is not sensitive to the complex \nbackground of wheat lodging. Mask-RT-DETR achieves a balance be -\ntween detection accuracy and computational efficiency through the \ncollaborative optimization of feature enhancement and spatial correla -\ntion modeling, and verifies the long-range dependence modeling ability \nof Transformer architecture on wheat lodging features. It shows the \nrationality of Mask-RT-DETR as a benchmark model.\n4.4. Model detection effect\nIn order to intuitively show the improvement of the improved model \non wheat lodging detection, Fig. 7 shows the detection results of the \noriginal model and the improved model using different Dataset training. \nThe improved model accurately identified the stem base damage area \n(covering the complete breaking point) after Dataset3 training, which \nproved the enhancement effect of the improved module on the key \nfeatures.\nIn order to verify the effect of the improved module on enhancing the \nfeature extraction of wheat stem breaking point, this study used Grad- \nCAM heat map technology to analyze the changes of the model \u2019 s \nattention to the feature region in different training stages ( Fig. 8 ). The \nexperimental results show that when training on the Dataset1 dataset, \nthe BCKM module significantly enhances the feature response to the \narea around the stem breaking point (about 1.2 cm < sup > 2 < /sup > ) in \nthe underlying feature layer (P2). When the Dataset2 data containing \nmulti-spectral information is introduced, the sensitivity of BCKM in the \nlodging area of the middle feature layer (P3) is significantly improved. \nAfter applying the Dataset3 data enhancement strategy, BCKM effec -\ntively integrates the stem direction and canopy continuity features by \nintroducing a cascade group attention (CGA) mechanism at the high- \nlevel semantic feature layer (P4). The heat map analysis showed that \nthe coincidence degree between the activation area of the model and the \nminimum circumscribed rectangle of the stem was significantly better \nthan that of the original module.\n4.5. Edge computing deployment test\nIn order to evaluate the reasoning ability of the improved model on \nUAV embedded devices, this study uses NVIDIA Jetson Orin Nano as the \ncore computing unit for deployment testing. The model transformation \nprocess is divided into three stages: First, the PyTorch model trained on \nthe PC is exported to the ONNX (Open Neural Network Exchange) in -\ntermediate format, and then FP16 quantization optimization is per -\nformed through the TensorRT engine, and finally an accelerated model \nadapted to Jetson Orin Nano is generated. Fig. 9 shows the hardware \nmonitoring interface and real-time detection effect after deployment. \nTable 5 shows the performance comparison between the improved \nmodel and the Jetson Orin Nano embedded platform on the PC side.\nIn this context, PT refers to the PyTorch model format, and TRT \ndenotes the model format optimized by TensorRT. Experiments show \nthat under the PC-side PyTorch format, the detection speed of the \nimproved model is 63.2 FPS, the accuracy rate is 97.2 %, and the recall \nrate is 96.7 %. After deploying to Jetson Orin Nano, the speed is reduced \nTable 2 \nAblation experiments of the improved model on dataset3.\nModel P/ % R/ % AP@.5 AP@.5:.95 FPS Parameters/M F1-score\nBaseline 91.1 85.9 0.851 0.757 42.7 32.8 88.4\n+ BCKM 92.9 89.4 0.853 0.761 69.5 15.6 91.1\n+ BCKM + CGA 95.3 94.2 0.944 0.782 67.8 16.2 94.8\n+ BCKM + CGA + Focal-EIoU Loss 97.2 96.7 0.958 0.796 63.2 16.9 96.9\nTable 3 \nPerformance on different datasets before and after improvement.\nModel Dataset P/ % R/ % AP@.5 AP@.5:.95 FPS F1- \nscore\nBaseline Dataset1 67.9 63.2 0.621 0.356 39.5 65.5\n\u200b Dataset2 79.5 75.0 0.754 0.515 41.5 77.2\n\u200b Dataset3 91.1 85.9 0.851 0.757 42.7 88.4\nOurs Dataset1 69.4 64.9 0.632 0.401 60.1 67.1\n\u200b Dataset2 81.2 76.7 0.763 0.554 62.4 78.9\n\u200b Dataset3 97.2 96.7 0.958 0.796 63.2 96.9\nTable 4 \nPerformance comparison of different models on dataset3.\nModel P/ % R/ % AP@.5 AP@.5:.95 FPS F1-score\nFaster R-CNN 66.5 61.2 0.743 0.537 16.6 63.7\nSSD 67.1 60.3 0.647 0.535 14.8 63.5\nYOLOv8n 82.9 79.0 0.862 0.602 69.2 80.9\nYOLOv9s 84.5 81.0 0.865 0.620 66.0 82.7\nYOLOv10n 86.0 82.0 0.866 0.630 64.0 84.0\nYOLOv11n 87.3 83.4 0.867 0.646 62.6 85.3\nYOLOv12n 88.5 84.8 0.870 0.660 61.0 86.6\nYOLOv13n 89.5 85.7 0.873 0.675 59.5 87.6\nMask-RT-DETR 91.1 85.9 0.851 0.757 42.7 88.4\nOurs 97.2 96.7 0.958 0.796 63.2 96.9\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n10 \nto 9.8 FPS (unaccelerated); after TensorRT acceleration, the detection \nspeed is increased to 32.0 FPS, but the accuracy is slightly reduced. The \naccuracy loss is because TensorRT uses an efficient numerical format to \naccelerate reasoning, and low-precision calculations introduce numeri -\ncal errors, which affects the prediction probability and accuracy. The \nresults show that through the optimization of TensorRT and the quan -\ntification of FP16, the lightweight model has successfully achieved a \nsignificant improvement in the reasoning speed (greater than 3 times \nacceleration) on the resource-constrained embedded platform, which \nmeets the real-time requirements of the UAV platform. Although the \naccuracy is slightly reduced by about 1 %, it is still within the acceptable \nrange, which effectively verifies the feasibility and superior perfor -\nmance of the lightweight model \u2019 s efficient deployment on embedded \ndevices.\n5. Discussion\n5.1. Technical advantages of model improvement\nThe improved Mask-RT-DETR model proposed in this study shows \nsignificant technical advantages in wheat lodging detection tasks, \nespecially in the combination of multi-spectral data and deep learning \nmethods, modular improvement and paradigm innovation of technical \nframework. Multispectral data plays a key role in improving the detec -\ntion accuracy of the model [ 18 ]. By introducing multi-spectral data into \nthe data set, the model can effectively capture the spectral anomaly \ncharacteristics of wheat lodging area, especially in the identification of \nstem breaking points, which significantly improves the adaptability of \nthe model to complex scenes. The experimental results show that the \nintroduction of multi-spectral data improves the accuracy of the model \nin the lodging area detection by 4.3 percentage points, which fully \nproves the importance of multi-spectral information in feature \nFig. 7. Detection results before and after model improvement.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n11 \nextraction.\nThe modular improvement strategy of the model plays an important \nrole in improving the detection accuracy and computational efficiency. \nFirstly, the bottleneck convolution kernel optimization module signifi -\ncantly enhances the spectral feature extraction ability of the stem \nbreaking point by 1 \u00d7 1 convolution compression channel and 3 \u00d7 3 \ndepth separable convolution, while reducing the number of model pa -\nrameters and improving the computational efficiency. The experimental \ndata show that the module reduces the calculation amount of the model \nby 32.5 %, while the detection accuracy is only reduced by 0.8 %, which \nachieves a good balance between accuracy and efficiency. Secondly, the \ncascaded group self-attention module (CGA) strengthens the modeling \nability of the model to the spatial distribution characteristics of the \nlodging area through the cascaded grouping strategy, especially when \ndealing with group occlusion and complex background. The introduc -\ntion of the CGA module reduces the missed detection rate of the model in \ncomplex scenes by 5.9 %. Finally, the Focal-EIoU loss function improves \nthe accuracy of bounding box regression by dynamic sample matching \nFig. 8. Comparison of heat maps between the original model and the improved model.\nFig. 9. Effect of model deployment on Jetson Orin Nano.\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n12 \nand difficult sample focusing strategy, which effectively alleviates the \nproblem of class imbalance. Experiments show that the Focal-EIoU loss \nfunction reduces the bounding box regression error of the model by 12.4 \n%, and further improves the detection accuracy.\nThe technical framework of this study provides a new paradigm for \nwheat lodging monitoring. In the combination of multi-spectral data and \ndeep learning model, the model can play the role of spectral features in \nlodging detection and provide a basis for subsequent optimization. In \naddition, the framework can also be extended to the lodging detection of \nother crops to provide technical support for precision agriculture man -\nagement. However, there is a certain deviation in the response of the \ncurrent model in different geographical regions. The next research needs \nto establish a detection and calibration mechanism based on cross- \necological region transfer learning to further improve the generaliza -\ntion ability of the model [ 25 ].\n5.2. Detection challenges in complex backgrounds\nIn practical applications, wheat lodging detection faces significant \ninterference from complex backgrounds in the field, such as weeds, soil \ntype diversity, group occlusion, and shade occlusion. These factors pose \nsevere challenges to the detection accuracy of the model. Especially \nunder the condition of high vegetation coverage [ 40 ], the difference of \nspectral characteristics between the lodging area and the surrounding \nenvironment is small, which leads to the decrease of target separability. \nIn addition, the diversity of stem bending angles further increases the \ndifficulty of detection, especially in the group lodging scene, the mutual \nocclusion between stems makes feature extraction more complicated \n[ 21 ]. This study effectively addresses these challenges by introducing a \ncascade group self-attention module (CGA) and a Focal-EIoU loss func -\ntion. The CGA module strengthens the modeling ability of the model for \nthe spatial distribution characteristics of the lodging area through the \ncascade grouping strategy, especially showing strong robustness when \ndealing with group occlusion. The experimental results show that the \nCGA module reduces the missed detection rate of the model in complex \nbackground by 5.9 %, which significantly improves the detection sta -\nbility. The Focal-EIoU loss function improves the accuracy of bounding \nbox regression by dynamic sample matching and difficult sample \nfocusing strategy, and effectively alleviates the problem of class imbal -\nance.The experimental data show that the Focal-EIoU loss function re -\nduces the bounding box regression error of the model by 12.4 %, which \nfurther improves the detection accuracy.\nHowever, the performance of the model under extreme conditions \nstill has some limitations. For example, under extreme light or meteo -\nrological conditions, the quality of multi-spectral data may be signifi -\ncantly affected, resulting in a decrease in detection accuracy [ 32 ]. \nEspecially in strong light or rainy weather, the stability of spectral \ncharacteristics is reduced, which increases the risk of false detection and \nmissed detection of the model. In addition, the diversity of complex \nbackground in the field also puts forward higher requirements for the \ngeneralization ability of the model [ 37 ]. Future research needs to further \nexplore multimodal data fusion strategies, such as combining visible \nlight and infrared data, to enhance the robustness of the model under \ndifferent environmental conditions. At the same time, the introduction \nof physical model-assisted feature extraction, such as the spectral \ncorrection method based on the radiative transfer model [ 14 ], may \nfurther improve the detection performance of the model in complex \nbackgrounds.\n5.3. Optimization and deployment challenges of edge computing\nWith the rapid development of agricultural monitoring technology, \nthe application of edge computing in UAV inspection has become the \nkey to realize real-time detection and efficient data processing [ 26 ]. In \nthis study, the improved Mask-RT-DETR model is deployed on the Jetson \nOrin Nano embedded device, and the TensorRT acceleration technology \nis used to significantly improve the inference efficiency of the model. \nThe experimental results show that after quantization and optimization, \nthe inference speed of the model reaches 32 frames per second, which \nfully meets the needs of UAV real-time inspection [ 29 ]. At the same \ntime, the deployment of the model on edge devices realizes the effective \nutilization of computing resources and significantly reduces the cost of \ndata transmission and storage. However, the optimization of edge \ncomputing also faces a series of challenges. Firstly, the limitation of \nhardware resources puts forward higher requirements for model \ncompression and quantization. Although the bottleneck convolution \nkernel optimization module effectively reduces the number of model \nparameters, there is still a certain accuracy loss in the quantization \nprocess.The experimental data show that the detection accuracy of the \nmodel on edge devices is 0.8 % lower than that of the original version, \nwhich indicates that a better balance between accuracy and efficiency is \nneeded. Secondly, the power consumption and endurance of edge de -\nvices are also urgent problems to be solved. The development and \noptimization of low-power edge computing chips will become an \nimportant direction for future research to further improve the opera -\ntional efficiency and endurance of UAV inspection.\nIn addition, the deployment of the model on edge devices also faces \nthe challenge of environmental adaptability. For example, in harsh en -\nvironments such as high temperature and high humidity, the stability of \nedge devices may be affected, which may lead to a decrease in detection \nperformance [ 9 ]. Future research needs to combine environmental \nmonitoring data and equipment performance optimization strategies to \nbuild a more robust edge computing framework. At the same time, an \nadaptive parameter adjustment mechanism based on edge devices is \ndeveloped, which can dynamically optimize the performance of the \nmodel according to environmental changes, and further improve the \ndetection accuracy and stability.\n5.4. Promotion value and future prospect of technical framework\nThe technical framework proposed in this study not only achieved \nremarkable results in the wheat lodging detection task, but also pro -\nvided an important paradigm reference for other agricultural moni -\ntoring tasks. Firstly, this study combines multi-spectral data with deep \nlearning models to achieve efficient detection of complex scenes. This \nparadigm can be extended to other crop diseases, pests and growth \nstatus monitoring, and provide technical support for precision agricul -\nture management. For example, in rice disease detection, multi-spectral \ndata can effectively capture the spectral anomaly characteristics of the \ndisease area [ 30 ], and combined with the deep learning model, \nhigh-precision disease identification and location can be achieved. \nSecondly, the introduction of embedded edge computing devices pro -\nvides a process adaptation scheme for the processing of UAV \nmulti-spectral data, which has extensive migration value for the same \ntype of agricultural monitoring tasks around the world. For example, in \nthe detection of maize lodging, the framework can achieve efficient \ndetection and accurate positioning by adjusting the data acquisition \nscheme and lightweight model structure [ 36 ]. In addition, the technical \nframework of this study can also be applied to non-agricultural fields \nsuch as forest fire monitoring and wetland ecological assessment to \nfurther expand its application scope.\nTable 5 \nModel deployment performance comparison.\nModel Platform Model format P/ % R/ % FPS\nMask-RT-DETR RTX 5090 PT 91.1 85.9 42.7\nJetson Orin Nano PT 91.1 85.3 7.6\nJetson Orin Nano TRT 89.4 85.3 21.2\nOurs RTX 5090 PT 97.2 96.7 63.2\nJetson Orin Nano PT 97.0 96.5 9.8\nJetson Orin Nano TRT 96.3 96.5 32.0\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n13 \nHowever, the promotion of the technical framework still faces a se -\nries of challenges. First of all, the difference between different crops and \ngeographical regions puts forward higher requirements for the gener -\nalization ability of the model. For example, different crops have signif -\nicant differences in spectral characteristics, growth cycle and \nenvironmental adaptability [ 23 ], and model parameters and training \nstrategies need to be adjusted accordingly. Future research needs to \nestablish a detection and calibration mechanism based on \ncross-ecological zone transfer learning to further improve the general -\nization ability of the model. Secondly, the fusion and optimization of \nmulti-modal data is also an important direction for the promotion of \ntechnical framework. The combination of visible light, infrared and \nradar data can capture the feature information of the target area more \ncomprehensively and improve the detection accuracy and stability [ 45 ]. \nIn addition, the collaborative optimization of edge computing and cloud \ncomputing will provide more efficient technical support for large-scale \nagricultural monitoring [ 6 ]. By constructing a computing framework \nbased on edge-cloud collaboration, efficient data processing and storage \ncan be achieved, and monitoring efficiency can be further improved.\n6. Conclusions\nThis study proposes a drone-based wheat lodging inspection system \nutilizing an improved Mask-RT-DETR model. By incorporating a \nbottleneck convolutional kernel optimization module, a cascaded \ngrouped self-attention (CGA) module, and the Focal-EIoU loss function, \nthe model achieves significant improvements in both accuracy and ef -\nficiency for wheat lodging detection. Experimental results show that the \nimproved model reaches a precision of 97.2 % on the test set, with \ndetection speed increased to 63.2 FPS\u2014representing a 6.7 percentage \npoint improvement in precision over the original model. In cross-model \ncomparative experiments, the proposed method outperforms Faster R- \nCNN, SSD, YOLOv8, YOLOv11, and the original Mask-RT-DETR in key \nmetrics including precision (P), recall (R), mean average precision \n(mAP), and F1-score, demonstrating particularly outstanding perfor -\nmance in accurately identifying lodged areas. Furthermore, the opti -\nmized model was successfully deployed on the Jetson Orin Nano \nembedded platform, achieving real-time detection at 32.0 FPS using \nTensorRT acceleration, while maintaining an accuracy of 96.3 % and a \nrecall of 96.5 %, thus meeting the dual requirements of real-time per -\nformance and high accuracy for drone-based inspection. The experi -\nments confirm that the improved model retains a lightweight \narchitecture while exhibiting strong capability in lodging detection, \noffering an effective technical solution for real-time monitoring of wheat \nlodging disasters and precision agricultural management. Future work \nwill focus on enhancing the model\u2019s robustness in multi-spectral data \nfusion and complex background scenarios, as well as exploring its \napplicability to lodging detection in other crops, thereby providing \nbroader technical support for agricultural disaster monitoring.\nEthical statement\nI certify that this manuscript is original and has not been published \nand will not be submitted elsewhere for publication while being \nconsidered by Smart Agricultural Technology. And the study is not split up \ninto several parts to increase the quantity of submissions and submitted \nto various journals or to one journal over time. No data have been \nfabricated or manipulated (including images) to support your conclu -\nsions. No data, text, or theories by others are presented as if they were \nour own.\nThe submission has been received explicitly from all co-authors. And \nauthors whose names appear on the submission have contributed suf -\nficiently to the scientific work and therefore share collective re -\nsponsibility and accountability for the results.\nCRediT authorship contribution statement\nChengchen Pan: Data curation, Formal analysis, Funding acquisi -\ntion, Project administration, Supervision, Visualization, Validation, \nWriting \u2013 review & editing. Jiyuan Xie: Writing \u2013 review & editing, \nWriting \u2013 original draft, Visualization, Validation, Methodology, Inves -\ntigation, Formal analysis, Data curation, Conceptualization. Gan Zhang: \nResources, Funding acquisition. Tao Cheng: Supervision, Visualization, \nValidation, Writing \u2013 review & editing. Dong Han: Supervision, Visu -\nalization, Validation, Writing \u2013 review & editing. Qiyu Fang: Writing \u2013 \nreview & editing. Shucun Ju: Writing \u2013 review & editing, Supervision, \nProject administration, Conceptualization. Dongyan Zhang: Writing \u2013 \nreview & editing, Writing \u2013 original draft, Supervision, Project admin -\nistration, Funding acquisition, Conceptualization.\nDeclaration of competing interest\nThe authors declare that they have no known competing financial \ninterests or personal relationships that could have appeared to influence \nthe work reported in this paper.\nAcknowledgments\nThe work was financially supported by the Inner Mengolia Science & \nTechnology Plan (2023YFHH0046), Shaanxi Qinchuang Park cited high- \nlevel innovation and entrepreneurship talent project (Grant No \nQCYRCXM-2023\u2013101), Sanqin Outstanding Talents Introduction Pro -\ngram (Outstanding Young Engineering and Technical Talents Project) \nand Talent research funding of Northwest A&F University.\nData availability\nData will be made available on request.\nReferences\n[1] N. Ali, et al., LodgeNet: an automated framework for precise detection and \nclassification of wheat lodging severity levels in precision farming, Front. Plant Sci. \n14 (2023) 1255961 .\n[2] T.T. Ayanlade, et al., Multi-modal AI for Ultra-Precision Agriculture, Harnessing \nData Science for Sustainable Agriculture and Natural Resource Management, \nSpringer, 2024, pp. 299\u2013334 .\n[3] R. Bertoglio, et al., On-the-go table grape ripeness estimation via proximal \nsnapshot hyperspectral imaging, Comput. Electron. Agric. 226 (2024) 109354 .\n[4] M. Buda, A. Maki, M.A. Mazurowski, A systematic study of the class imbalance \nproblem in convolutional neural networks, Neural Netw. 106 (2018) 249\u2013259 .\n[5] M. Capra, R. Peloso, G. Masera, M. Ruo Roch, M. Martina, Edge computing: a \nsurvey on the hardware requirements in the internet of things world, Future \nInternet. 11 (4) (2019) 100 .\n[6] C. Ding, et al., A cloud-edge collaboration framework for cognitive service, IEEE \nTrans. Cloud Comput. 10 (3) (2020) 1489\u20131499 .\n[7] H. Guan, et al., A quantitative monitoring method for determining maize lodging in \ndifferent growth stages, Remote Sens. 12 (19) (2020) 3149 .\n[8] I. Gultepe, et al., A review of high impact weather for aviation meteorology, Pure \nAppl. Geophys. 176 (5) (2019) 1869\u20131921 .\n[9] A. Hassan, Y. Savaria, M. Sawan, Electronics and packaging intended for emerging \nharsh environment applications: a review, IEEe Trans. Very. Large Scale Integr. \nVLSI. Syst. 26 (10) (2018) 2085\u20132098 .\n[10] J. Hu, G. Zhang, M. Shen, W. Li, Detecting surface defects of pine wood using an \nimproved RT-DETR model, Trans. Chin. Soc. Agric. Eng. 40 (2024) 210\u2013218 .\n[11] L. Hu, X. Li, Apple recognition in complex environments based on FC-DETR, \nHeliyon. 10 (18) (2024) .\n[12] G. Huang, et al., Identifying key factors influencing maize stalk lodging resistance \nthrough wind tunnel simulations with machine learning algorithms, Artif. Intell. \nAgric. 15 (2) (2025) 316\u2013326 .\n[13] Y. Huang, et al., A lightweight citrus ripeness detection algorithm based on visual \nsaliency priors and improved RT-DETR, Agronomy 15 (5) (2025) 1173 .\n[14] R.A.F. Ishaq, et al., A systematic review of radiative transfer models for crop yield \nprediction and crop traits retrieval, Remote Sens. 16 (1) (2023) 121 .\n[15] R. Jiao, B.H. Nguyen, B. Xue, M. Zhang, A survey on evolutionary multiobjective \nfeature selection in classification: approaches, applications, and challenges, IEEE \nTrans. Evol. Comput. 28 (4) (2023) 1156\u20131176 .\n[16] S. Jin, L. Zhou, H. Zhou, CO-YOLO: a lightweight and efficient model for Camellia \noleifera fruit object detection and posture determination, Comput. Electron. Agric. \n235 (2025) 110394 .\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n14 \n[17] W. Jinlong, W. Hongqi, L. Hao, L. Xingpeng, S. Haiyan, Segmentation of buckwheat \nby UAV based on improved lightweight DeepLabV3 + at seedling stage, Nongye \nJixie Xuebao/Trans. Chin. Soc. Agric. Mach. 55 (5) (2024) .\n[18] X. Jiyuan, et al., Accurate detection of tree planting locations in Inner Mongolia for \nthe Three North project based on YOLOv10-MHSA, Smart Agric. (2025) 1 .\n[19] M. Kumar, B.K. Bhattacharya, M.R. Pandya, B. Handique, Machine learning based \nplot level rice lodging assessment using multi-spectral UAV remote sensing, \nComput. Electron. Agric. 219 (2024) 108754 .\n[20] J. Li, et al., SoybeanNet: transformer-based convolutional neural network for \nsoybean pod counting from Unmanned Aerial Vehicle (UAV) images, Comput. \nElectron. Agric. 220 (2024) 108861 .\n[21] Q. Li, et al., Crop lodging and the roles of lignin, cellulose, and hemicellulose in \nlodging resistance, Agronomy 12 (8) (2022) 1795 .\n[22] F. Liu, et al., Detection of heterogeneity in multi-spectral transmission image based \non spatial pyramid matching model and deep learning, Opt. Lasers. Eng. 134 \n(2020) 106272 .\n[23] N. Liu, et al., Growth stages classification of potato crop based on analysis of \nspectral response and variables optimization, Sensors 20 (14) (2020) 3995 .\n[24] S. Liu, W. Yue, Z. Guo, L. Wang, Multi-branch CNN and grouping cascade attention \nfor medical image classification, Sci. Rep. 14 (1) (2024) 15013 .\n[25] N. Mangra, et al., INGR Roadmap Applications and Services chapter, in: 2023 IEEE \nFuture Networks World Forum (FNWF), IEEE, 2023, pp. 1 \u2013 186 .\n[26] P. McEnroe, S. Wang, M. Liyanage, A survey on the convergence of edge computing \nand AI for UAVs: opportunities and challenges, IEEe Internet. Things. J. 9 (17) \n(2022) 15435 \u2013 15459 .\n[27] R.U. Modi, et al., State-of-the-art computer vision techniques for automated \nsugarcane lodging classification, Field. Crops. Res. 291 (2023) 108797 .\n[28] S. Nithin, et al., Importance of condition monitoring in mechanical domain, Mater. \nToday: Proc. 54 (2022) 234 \u2013 239 .\n[29] M.D. Phung, T.H. Dinh, Q.P. Ha, System architecture for real-time surface \ninspection using multiple UAVs, IEEe Syst. J. 14 (2) (2019) 2925 \u2013 2936 .\n[30] K. Sharada, et al., GeoAgriGuard: aI-driven pest and disease management with \nremote sensing for global food security, Remote Sens. Earth. Syst. Sci. 8 (2) (2025) \n409 \u2013 422 .\n[31] D. Shi, Z. Guorui, G. Hao, W. Jian, L. Chen, Identifying cucumber fruits during \nselective picking using improved RT-detr, Trans. Chin. Soc. Agric. Eng. 41 (1) \n(2025) 212 \u2013 220 .\n[32] Y. Shi, B. Fu, N. Wang, Y. Chen, J. Fang, Multispectral image quality improvement \nbased on global iterative fusion constrained by meteorological factors, Cognit. \nComput. 16 (1) (2024) 404 \u2013 424 .\n[33] J. Sun, J. Zhou, Y. He, H. Jia, Z. Liang, RL-DeepLabv3 + : a lightweight rice lodging \nsemantic segmentation model for unmanned rice harvester, Comput. Electron. \nAgric. 209 (2023) 107823 .\n[34] S. Tan, A.K. Mortensen, X. Ma, B. Boelt, R. Gislum, Assessment of grass lodging \nusing texture and canopy height distribution features derived from UAV visual- \nband images, Agric. For. Meteorol. 308 (2021) 108541 .\n[35] P. Vasanthi, L. Mohan, Ensemble of ghost convolution block with nested \ntransformer encoder for dense object recognition, Biomed. Signal. Process. Control \n88 (2024) 105645 .\n[36] D. Wang, et al., Classification of maize lodging types using UAV-SAR remote \nsensing data and machine learning methods, Comput. Electron. Agric. 227 (2024) \n109637 .\n[37] J. Wang, et al., Generalizing to unseen domains: a survey on domain \ngeneralization, IEEe Trans. Knowl. Data Eng. 35 (8) (2022) 8052 \u2013 8072 .\n[38] L. Wang, H. Xiao, A grid-level segmentation model based on encoder-decoder \nstructure with multi-source features for crop lodging detection, Appl. Soft. Comput. \n151 (2024) 111113 .\n[39] P.-Y. Wang, C.-T. Chen, J.-W. Su, T.-Y. Wang, S.-H. Huang, Deep learning model for \nhouse price prediction using heterogeneous data analysis along with joint self- \nattention mechanism, IEEe Access. 9 (2021) 55244 \u2013 55259 .\n[40] J. Xie, et al., Accurate UAV-based detection of planting pits via spectral-spatial \ndual-domain collaboration, Smart Agric. Technol. (2025) 101384 .\n[41] J. Xie, et al., Coupling crop growth models and machine learning for scalable \nwinter wheat yield estimation across major wheat regions in China, Agric. For. \nMeteorol. 372 (2025) 110687 .\n[42] J. Xu, S. Xu, M. Ma, J. Ma, C. Li, Research and implementation of travel aids for \nblind and visually impaired people, Sensors 25 (14) (2025) 4518 .\n[43] J. Yu, et al., Real-time smoke detection with split top-K transformer and adaptive \ndark channel prior in foggy environments, IEEe Internet. Things. J. (2024) .\n[44] F. Zeng, et al., Growth monitoring of rapeseed seedlings in multiple growth stages \nbased on low-altitude remote sensing and semantic segmentation, Comput. \nElectron. Agric. 232 (2025) 110135 .\n[45] W. Zhang, X. Fu, W. Li, The intelligent vehicle target recognition algorithm based \non target infrared features combined with lidar, Comput. Commun. 155 (2020) \n158 \u2013 165 .\n[46] Y.-F. Zhang, et al., Focal and efficient IOU loss for accurate bounding box \nregression, Neurocomputing. 506 (2022) 146 \u2013 157 .\n[47] B. Zhao, et al., Performance optimization of lightweight transformer architecture \nfor cherry tomato picking, Trans. Chin. Soc. Agric. Mach. 55 (10) (2024) 62 \u2013 71, \n105 .\n[48] Z. Zhao, et al., Rt-detr-tomato: tomato target detection algorithm based on \nimproved rt-detr for agricultural safety production, Appl. Sci. 14 (14) (2024) 6287 .\n[49] L. Zhou, et al., Soybean yield estimation and lodging classification based on UAV \nmulti-source data and self-supervised contrastive learning, Comput. Electron. \nAgric. 230 (2025) 109822 .\nC. Pan et al.                                                                                                                                                                                                                                      Smart Agricultural Technology 12 (2025) 101509 \n15 "}