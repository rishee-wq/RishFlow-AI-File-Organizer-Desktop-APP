{"mtime": 1764349409.5255291, "text": "All Readings:IntroductiontoGenerativeAI\nKindly note that the 30minutes indicatedonthepla\u0000ormconsiders thetimethat it maytake you to browse through the reading resources provided. The total time requireddependsonthereadingsyoudecidetoexplorefu\u0000her.\nAssembledreadingsongenerativeAI:\n\u25cf AskaTechspe\u0000: What isgenerativeAI?h\u0000ps://blog.google/inside-google/googlers/ask-a-techspe\u0000/what-is-generative-ai/\n\u25cf What isgenerativeAI?h\u0000ps://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-generative-ai\n\u25cf GoogleResearch, 2022&beyond: Generativemodels:h\u0000ps://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html#GenerativeModels\n\u25cf Buildingthemost openandinnovativeAI ecosystem:h\u0000ps://cloud.google.com/blog/products/ai-machine-learning/building-an-open-generative-ai-pa\u0000ner-ecosystem\n\u25cf GenerativeAI ishere. WhoShouldControl It?h\u0000ps://www.nytimes.com/2022/10/21/podcasts/hard-fork-generative-a\u0000i\u0000cial-intelligence.html\n\u25cf StanfordU&Google\u2019sGenerativeAgentsProduceBelievableProxiesofHumanBehaviors:h\u0000ps://syncedreview.com/2023/04/12/stanford-u-googles-generative-agents-produce-believable-proxies-of-human-behaviours/\n\u25cf GenerativeAI: PerspectivesfromStanfordHAI:h\u0000ps://hai.stanford.edu/sites/default/\u0000les/2023-03/Generative_AI_HAI_Perspectives\n\u25cf GenerativeAI at Work:h\u0000ps://www.nber.org/system/\u0000les/working_papers/w31161/w31161.pdf\n\u25cf ThefutureofgenerativeAI isniche, not generalized:h\u0000ps://www.technologyreview.com/2023/04/27/1072102/the-future-of-generative-ai-is-niche-not-generalized/\n\n\u25cf TheimplicationsofGenerativeAI forbusinesses:h\u0000ps://www2.deloi\u0000e.com/us/en/pages/consulting/a\u0000icles/generative-a\u0000i\u0000cial-intelligence.html\n\u25cf ProactiveRiskManagement inGenerativeAI:h\u0000ps://www2.deloi\u0000e.com/us/en/pages/consulting/a\u0000icles/responsible-use-of-generative-ai.html\n\u25cf HowGenerativeAI IsChangingCreativeWork:h\u0000ps://hbr.org/2022/11/how-generative-ai-is-changing-creative-work\nAssembledreadingsonlargelanguagemodels:\n\u25cf NLP'sImageNet moment hasarrived: h\u0000ps://thegradient.pub/nlp-imagenet/\n\u25cf LaMDA: ourbreakthroughconversationtechnology:h\u0000ps://blog.google/technology/ai/lamda/\n\u25cf LanguageModelsareFew-Shot Learners:h\u0000ps://proceedings.neurips.cc/paper/2020/\u0000le/1457c0d6bfcb4967418b\u00008ac142f64a-Paper.pdf\n\u25cf IntroducingGemini: ourlargest andmost capableAI model:h\u0000ps://blog.google/technology/ai/google-gemini-ai/#sundar-note\n\u25cf ThePowerofScaleforParameter-E\u0000cient Prompt Tuning:h\u0000ps://arxiv.org/pdf/2104.08691.pdf\n\u25cf GoogleResearch, 2022&beyond: Languagemodels:h\u0000ps://ai.googleblog.com/2023/01/google-research-2022-beyond-language.html#LanguageModels\n\u25cf Solvingamachine-learningmystery:h\u0000ps://news.mit.edu/2023/large-language-models-in-context-learning-0207\nAdditional Resources:\n\u25cf A\u0000entionisAll YouNeed: h\u0000ps://research.google/pubs/pub46201/\n\u25cf Transformer: ANovel Neural NetworkArchitectureforLanguageUnderstanding:h\u0000ps://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\n\u25cf TransformeronWikipedia:\nh\u0000ps://en.wikipedia.org/wiki/Transformer_(machine_learning_model)#:~:text=Transformers%20were%20introduced%20in%202017,allowing%20training%20on%20larger%20datasets.\n\u25cf What isTemperatureinNLP?h\u0000ps://lukesalamone.github.io/posts/what-is-temperature/\n\u25cf Model Garden: h\u0000ps://cloud.google.com/model-garden\n\u25cf Auto-generatedSummariesinGoogleDocs:h\u0000ps://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html"}