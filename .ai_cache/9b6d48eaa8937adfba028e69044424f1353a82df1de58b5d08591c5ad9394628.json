{"mtime": 1760894946.0173442, "text": "02013\nReal-Time Face Mask Detection Using Deep Learning: En-\nhancing Public Health and Safety\nRatnam Dodda1,\u2217, Raghavendra C.1,\u2217\u2217, Raghavendra Swamy U.1,\u2217\u2217\u2217, Chandu Naik\nAzmera1,\u2217\u2217\u2217\u2217, Sreenu M1,\u2020, and Satyanarayana Nimmala1,\u2021\n1CVR College of Engineering, Hyderabad, India.\nAbstract. This paper presents a deep learning-based system for real-time face\nmask detection, aimed at enhancing public health monitoring in environments\nwhere mask compliance is critical. Utilizing a Convolutional Neural Network\n(CNN) built with TensorFlow and Keras, the model effectively classifies indi-\nviduals as mask-wearing or non-mask-wearing. Data preprocessing and aug-\nmentation techniques improve the model\u2019s robustness across diverse input im-\nages, ensuring high performance and generalizability. Developed on Google\nColab, the system leverages cloud-based resources for efficient model train-\ning and deployment, eliminating the need for extensive local hardware. It sup-\nports real-time image analysis and is scalable for continuous video monitoring,\nmaking it suitable for large-scale applications. Integration with Google Drive\nstreamlines data management, simplifying updates and deployment. The pro-\nposed system provides an accessible solution for mask compliance monitoring\nin public spaces, offering accuracy, scalability, and ease of deployment. Fu-\nture work will focus on enhancing the system with multi-class classification for\nmask types, IoT integration for automated responses, and edge device deploy-\nment to improve accessibility. This tool demonstrates the potential of AI in\npromoting health and safety in public settings.\n1 Introduction\nThe rise of global health crises, including COVID-19, has underscored the urgent need for\ntechnologies that enhance public safety and reinforce health protocols[1]. Face masks have\nproven essential in reducing the transmission of airborne pathogens, yet large-scale compli-\nance remains a logistical challenge. This face mask detection project addresses this need\nby developing an automated system that accurately identifies individuals with and without\nmasks in real-time[2].\nEmploying a Convolutional Neural Network (CNN) model for image classification, this\nsystem integrates deep learning and computer vision to detect mask compliance in various\n\u2217e-mail: ratnam.dodda@gmail.com\n\u2217\u2217e-mail: crg.svch@gmail.com\n\u2217\u2217\u2217e-mail: raghava5450@cvr.ac.in\n\u2217\u2217\u2217\u2217e-mail: azmerachandunaik@cvr.ac.in\n\u2020e-mail: pittunaik723@gmail.com\n\u2021e-mail: satyauce234@gmail.com\n\u00a9 The Authors, published by EDP Sciences. This is an open access article distributed under the terms of the Creative Commons \nAttribution License 4.0 (https://creativecommons.org/licenses/by/4.0/).\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nhigh-traffic environments, including airports, public transportation, corporate offices, educa-\ntional institutions, and healthcare facilities[3]. Automation reduces reliance on personnel for\nmonitoring and ensures a consistent, non-invasive approach to enforcing safety measures[4].\nThe project offers a scalable, adaptable solution that extends beyond the pandemic re-\nsponse, applicable in laboratory settings, clean rooms, and hazardous environments where\nmasks are mandatory for safety. By leveraging TensorFlow, Keras, and OpenCV , this ini-\ntiative illustrates the potential of artificial intelligence to develop practical tools that actively\ncontribute to global public health and safety efforts[5][6].\n1.1 Literature Survey\nThe COVID-19 pandemic underscored the need for effective monitoring of face mask com-\npliance, as manual surveillance methods proved labor-intensive and susceptible to human\nerror. Initial technological approaches utilized classical computer vision methods, such as\nHaar cascades and Histogram of Oriented Gradients (HOG) combined with Support V ector\nMachines (SVM), to detect objects like face masks. Although these methods offered founda-\ntional solutions, they faced limitations in adapting to complex, dynamic environments due to\ntheir rigidity and reliance on handcrafted features[7].\nWith advancements in deep learning, particularly Convolutional Neural Networks\n(CNNs), image classification and object detection tasks have seen substantial improvements\nin accuracy and adaptability. Studies like Wang & Qian (2020) have demonstrated that CNN-\nbased systems outperform traditional machine learning models in both real-time mask detec-\ntion and accuracy. Furthermore, hybrid models utilizing transfer learning, such as those by\nLoey et al. (2021), have shown that pre-trained architectures like MobileNet and VGG16 en-\nhance feature extraction, thus improving detection robustness while reducing training time[8].\nModern frameworks like YOLO (Y ou Only Look Once), as explored by Redmon &\nFarhadi (2018), offer real-time detection capabilities suitable for high-speed applications,\nthough their computational demands can be high. Simpler custom CNN architectures pro-\nvide a balanced solution for environments with limited resources, maintaining accuracy\nwhile reducing computational load. Techniques such as data augmentation and model tun-\ning are essential for handling variability in data\u2014including face angles, lighting, and image\nquality\u2014allowing these models to deliver reliable, generalizable results for real-time public\nhealth monitoring applications[9].\n2 Methodology\nThe proposed automated face mask detection system utilizes a Convolutional Neural Net-\nwork (CNN) model designed to classify images into two categories: \"with mask\" and \"with-\nout mask.\" The process begins with a comprehensive dataset of images featuring individuals\nboth wearing and not wearing masks. Preprocessing techniques are applied, including resiz-\ning images to a standard 150x150 pixels and normalizing pixel values to optimize model per-\nformance. To enhance generalization, data augmentation techniques such as rotation, zoom,\nand horizontal flipping increase dataset diversity[10].\nThe CNN model architecture comprises several convolutional layers interspersed with\nmax-pooling layers to extract and refine features from the input images. These are followed\nby fully connected layers that produce the final classification output[11]. The model is trained\nusing a binary cross-entropy loss function paired with the Adam optimizer, supporting effec-\ntive convergence. For validation, the dataset is split into training and validation subsets to\nmonitor accuracy and loss throughout training[12].\nOnce trained, the model can be deployed in real-time applications, taking input from\nlive cameras or image files and providing mask detection predictions. The output can be\nintegrated into surveillance systems or access control systems, supporting public health\ncompliance[13]. The system also incorporates feedback mechanisms to allow periodic re-\ntraining with new data, enabling adaptation to varying mask types and evolving usage pat-\nterns. This method prioritizes high accuracy and operational efficiency, making it effective in\ndiverse environments while supporting health and safety initiatives[14].\nFig 1. Flowchart for ReLU and Dropout Layers Work in CNNs\nThe face mask detection system leverages a range of advanced technologies, each integral\nto its functionality and deployment[13]. At the core is a deep learning model using convolu-\ntional Neural Networks (CNNs), chosen for their strong performance in image classification\ntasks. The CNN architecture in this project includes Conv2D layers for feature extraction,\nMaxPooling2D layers for down-sampling, and dense layers for classification, enabling accu-\nrate identification of faces as masked or unmasked[10].\nFramework and Development Environment: The model is developed with TensorFlow\nas the primary framework, which offers comprehensive tools for building, training, and fine-\ntuning deep learning models. Integrated within TensorFlow, Keras simplifies the design and\nmanagement of the CNN, providing a flexible yet powerful development experience[15].\nCloud-Based Training and Deployment: Google Colab, a cloud-based platform, serves\nas the development and training environment, providing access to GPUs and TPUs to support\nhigh-performance training without requiring local hardware. This setup accelerates model\nprototyping and iteration. Data storage and model management are facilitated by Google\nDrive, ensuring efficient access and secure storage for datasets and trained models[16].\nSupporting Technologies: Python is the primary programming language used, along\nwith libraries like NumPy for data handling, Matplotlib for visualizing training metrics, and\nImageDataGenerator for data augmentation. These tools enrich the model\u2019s ability to gener-\nalize by enhancing dataset diversity and optimizing data preprocessing[17].\n2\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nhigh-traffic environments, including airports, public transportation, corporate offices, educa-\ntional institutions, and healthcare facilities[3]. Automation reduces reliance on personnel for\nmonitoring and ensures a consistent, non-invasive approach to enforcing safety measures[4].\nThe project offers a scalable, adaptable solution that extends beyond the pandemic re-\nsponse, applicable in laboratory settings, clean rooms, and hazardous environments where\nmasks are mandatory for safety. By leveraging TensorFlow, Keras, and OpenCV , this ini-\ntiative illustrates the potential of artificial intelligence to develop practical tools that actively\ncontribute to global public health and safety efforts[5][6].\n1.1 Literature Survey\nThe COVID-19 pandemic underscored the need for effective monitoring of face mask com-\npliance, as manual surveillance methods proved labor-intensive and susceptible to human\nerror. Initial technological approaches utilized classical computer vision methods, such as\nHaar cascades and Histogram of Oriented Gradients (HOG) combined with Support V ector\nMachines (SVM), to detect objects like face masks. Although these methods offered founda-\ntional solutions, they faced limitations in adapting to complex, dynamic environments due to\ntheir rigidity and reliance on handcrafted features[7].\nWith advancements in deep learning, particularly Convolutional Neural Networks\n(CNNs), image classification and object detection tasks have seen substantial improvements\nin accuracy and adaptability. Studies like Wang & Qian (2020) have demonstrated that CNN-\nbased systems outperform traditional machine learning models in both real-time mask detec-\ntion and accuracy. Furthermore, hybrid models utilizing transfer learning, such as those by\nLoey et al. (2021), have shown that pre-trained architectures like MobileNet and VGG16 en-\nhance feature extraction, thus improving detection robustness while reducing training time[8].\nModern frameworks like YOLO (Y ou Only Look Once), as explored by Redmon &\nFarhadi (2018), offer real-time detection capabilities suitable for high-speed applications,\nthough their computational demands can be high. Simpler custom CNN architectures pro-\nvide a balanced solution for environments with limited resources, maintaining accuracy\nwhile reducing computational load. Techniques such as data augmentation and model tun-\ning are essential for handling variability in data\u2014including face angles, lighting, and image\nquality\u2014allowing these models to deliver reliable, generalizable results for real-time public\nhealth monitoring applications[9].\n2 Methodology\nThe proposed automated face mask detection system utilizes a Convolutional Neural Net-\nwork (CNN) model designed to classify images into two categories: \"with mask\" and \"with-\nout mask.\" The process begins with a comprehensive dataset of images featuring individuals\nboth wearing and not wearing masks. Preprocessing techniques are applied, including resiz-\ning images to a standard 150x150 pixels and normalizing pixel values to optimize model per-\nformance. To enhance generalization, data augmentation techniques such as rotation, zoom,\nand horizontal flipping increase dataset diversity[10].\nThe CNN model architecture comprises several convolutional layers interspersed with\nmax-pooling layers to extract and refine features from the input images. These are followed\nby fully connected layers that produce the final classification output[11]. The model is trained\nusing a binary cross-entropy loss function paired with the Adam optimizer, supporting effec-\ntive convergence. For validation, the dataset is split into training and validation subsets to\nmonitor accuracy and loss throughout training[12].\nOnce trained, the model can be deployed in real-time applications, taking input from\nlive cameras or image files and providing mask detection predictions. The output can be\nintegrated into surveillance systems or access control systems, supporting public health\ncompliance[13]. The system also incorporates feedback mechanisms to allow periodic re-\ntraining with new data, enabling adaptation to varying mask types and evolving usage pat-\nterns. This method prioritizes high accuracy and operational efficiency, making it effective in\ndiverse environments while supporting health and safety initiatives[14].\nFig 1. Flowchart for ReLU and Dropout Layers Work in CNNs\nThe face mask detection system leverages a range of advanced technologies, each integral\nto its functionality and deployment[13]. At the core is a deep learning model using convolu-\ntional Neural Networks (CNNs), chosen for their strong performance in image classification\ntasks. The CNN architecture in this project includes Conv2D layers for feature extraction,\nMaxPooling2D layers for down-sampling, and dense layers for classification, enabling accu-\nrate identification of faces as masked or unmasked[10].\nFramework and Development Environment: The model is developed with TensorFlow\nas the primary framework, which offers comprehensive tools for building, training, and fine-\ntuning deep learning models. Integrated within TensorFlow, Keras simplifies the design and\nmanagement of the CNN, providing a flexible yet powerful development experience[15].\nCloud-Based Training and Deployment: Google Colab, a cloud-based platform, serves\nas the development and training environment, providing access to GPUs and TPUs to support\nhigh-performance training without requiring local hardware. This setup accelerates model\nprototyping and iteration. Data storage and model management are facilitated by Google\nDrive, ensuring efficient access and secure storage for datasets and trained models[16].\nSupporting Technologies: Python is the primary programming language used, along\nwith libraries like NumPy for data handling, Matplotlib for visualizing training metrics, and\nImageDataGenerator for data augmentation. These tools enrich the model\u2019s ability to gener-\nalize by enhancing dataset diversity and optimizing data preprocessing[17].\n3\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nFig 2. Three phase processing.\n3 Results and Discussion\nThe results of this paper highlight the effectiveness of the Convolutional Neural Network\n(CNN) model for face mask detection, with several key findings:\nHigh Training and V alidation Accuracy: The model achieved high accuracy throughout\ntraining and validation, demonstrating effective learning of essential mask detection features.\nThe final training accuracy approached nearly 100%, while validation accuracy consistently\nexceeded 90%, indicating the model\u2019s ability to generalize well across different images.\nSteady Loss Reduction: Both training and validation loss decreased consistently over\nepochs, confirming the model\u2019s success in minimizing error rates. This steady reduction\nhighlights the model\u2019s efficiency in refining its predictions, resulting in better accuracy and\nreliability on unseen data.\nReal-Time Detection Capability: Once deployed, the model demonstrated robust real-\ntime mask detection capabilities, producing quick and accurate predictions. This real-time\nfunctionality is crucial for public safety applications, where immediate feedback on mask\ncompliance is essential.\nRobustness and Stability: The model maintained strong performance even with minor\nfluctuations in validation metrics during certain epochs. This resilience indicates that the\nmodel is capable of effectively handling varied inputs, which supports its applicability in\ndiverse environments.\nScope for Future Improvements: While the current results are promising, opportunities\nremain for future enhancement. Incorporating more complex and varied datasets or refining\nthe model architecture could further boost performance, particularly in challenging detection\nscenarios.\nTraining and Validation Accuracy Graph:\nThis graph illustrates the model\u2019s training and validation accuracy progression over 10\nepochs. The training accuracy, represented by the blue line, consistently trends upward, indi-\ncating effective learning of the training data. Minor fluctuations in the line reflect optimizer\nadjustments aimed at enhancing learning. The validation accuracy, shown in orange, starts\nhigh but dips notably after the second epoch, suggesting potential overfitting or data-specific\nFig 3. Image without Mask.\nFig 4. Image with Mask.\nlearning challenges. However, validation accuracy recovers in later epochs, fluctuating close\nto the training accuracy, suggesting that the model retains a good capacity for generalization\nto unseen data.\nThe graph displays the training and validation loss of the model over 10 epochs. The\ntraining loss, represented in blue, begins at a relatively high level and steadily decreases as\nthe epochs progress, indicating that the model is effectively learning and reducing its error on\nthe training dataset. In contrast, the validation loss, shown in orange, starts out higher than\n4\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nFig 2. Three phase processing.\n3 Results and Discussion\nThe results of this paper highlight the effectiveness of the Convolutional Neural Network\n(CNN) model for face mask detection, with several key findings:\nHigh Training and V alidation Accuracy: The model achieved high accuracy throughout\ntraining and validation, demonstrating effective learning of essential mask detection features.\nThe final training accuracy approached nearly 100%, while validation accuracy consistently\nexceeded 90%, indicating the model\u2019s ability to generalize well across different images.\nSteady Loss Reduction: Both training and validation loss decreased consistently over\nepochs, confirming the model\u2019s success in minimizing error rates. This steady reduction\nhighlights the model\u2019s efficiency in refining its predictions, resulting in better accuracy and\nreliability on unseen data.\nReal-Time Detection Capability: Once deployed, the model demonstrated robust real-\ntime mask detection capabilities, producing quick and accurate predictions. This real-time\nfunctionality is crucial for public safety applications, where immediate feedback on mask\ncompliance is essential.\nRobustness and Stability: The model maintained strong performance even with minor\nfluctuations in validation metrics during certain epochs. This resilience indicates that the\nmodel is capable of effectively handling varied inputs, which supports its applicability in\ndiverse environments.\nScope for Future Improvements: While the current results are promising, opportunities\nremain for future enhancement. Incorporating more complex and varied datasets or refining\nthe model architecture could further boost performance, particularly in challenging detection\nscenarios.\nTraining and Validation Accuracy Graph:\nThis graph illustrates the model\u2019s training and validation accuracy progression over 10\nepochs. The training accuracy, represented by the blue line, consistently trends upward, indi-\ncating effective learning of the training data. Minor fluctuations in the line reflect optimizer\nadjustments aimed at enhancing learning. The validation accuracy, shown in orange, starts\nhigh but dips notably after the second epoch, suggesting potential overfitting or data-specific\nFig 3. Image without Mask.\nFig 4. Image with Mask.\nlearning challenges. However, validation accuracy recovers in later epochs, fluctuating close\nto the training accuracy, suggesting that the model retains a good capacity for generalization\nto unseen data.\nThe graph displays the training and validation loss of the model over 10 epochs. The\ntraining loss, represented in blue, begins at a relatively high level and steadily decreases as\nthe epochs progress, indicating that the model is effectively learning and reducing its error on\nthe training dataset. In contrast, the validation loss, shown in orange, starts out higher than\n5\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nFig 5. Model Accuracy chart.\nFig 6. Model Loss chart.\nthe initial training loss but rapidly drops below it after the first epoch. This initial decrease\nsuggests that the model is generalizing well to unseen data. However, fluctuations in the vali-\ndation loss occur in the subsequent epochs, indicating variability in the model\u2019s performance\non the validation dataset.\n4 Conclusion and Future Scope\nIn conclusion, the face mask detection paper marks a significant advancement in utilizing\ndeep learning technologies to enhance public health and safety. By implementing a Convolu-\ntional Neural Network (CNN) architecture with TensorFlow and Keras, the project effectively\nidentifies whether individuals are wearing masks in real-time. This system meets a critical\nneed in public spaces where mask mandates are in effect, facilitating efficient monitoring and\npromoting compliance.\nThe incorporation of data augmentation techniques further ensures that the model gener-\nalizes well, allowing it to adapt to diverse scenarios and varying image qualities for reliable\nperformance. Utilizing cloud resources such as Google Colab and Google Drive boosts the\nproject\u2019s scalability and accessibility. Google Colab provides powerful computational re-\nsources, enabling model training and testing without the limitations of local hardware, while\nGoogle Drive streamlines data storage and retrieval. This cloud-based approach not only\naccelerates the development process but also makes the solution suitable for large-scale de-\nployment in environments like airports, shopping centers, and schools. Future Scope The\nproject can be expanded by integrating real-time video surveillance for monitoring mask com-\npliance in public spaces and enhancing the model to classify different mask types. Deploy-\ning the system on edge devices like smartphones would enable real-time detection without\ncloud dependency. Further improvements could include adopting advanced architectures for\nhigher accuracy, detecting additional safety measures, and implementing a multi-language\nalert system. Additionally, integrating with IoT systems for automated responses, ensuring\ndata privacy, supporting low-bandwidth environments, and creating a user-friendly interface\nfor detailed reporting would enhance the project\u2019s effectiveness and accessibility.\nReferences\n1. A. Soetan, L. Zhang, Mitigating Infectious Disease Transmission with Face Mask De-\ntection Using Machine Learning, in 2023 IEEE Canadian Conference on Electrical and\nComputer Engineering (CCECE) (IEEE, 2023), pp. 423\u2013427\n2. C. Sudthongkhong, B. Intarapasan, T. Wongsheree, K. Thanasuan, B. Pattanapipat,\nP . Suksai, Real-Time Face Mask Detection with Deep Learning for Pandemic Safety,\nin 2023 17th International Conference on Signal-Image Technology & Internet-Based\nSystems (SITIS) (IEEE, 2023), pp. 213\u2013217\n3. A. Kanavos, O. Papadimitriou, K. Al-Hussaeni, M. Maragoudakis, I. Karamitsos, Real-\ntime detection of face mask usage using convolutional neural networks, Computers 13,\n182 (2024).\n4. J. Y edukondalu, T.Y . Singh, D. Sharma, R.S. Singh, L.D. Sharma, Face Mask Detection\nUsing Image Processing and Convolutional Neural Networks, in 2022 IEEE 6th Confer-\nence on Information and Communication Technology (CICT) (IEEE, 2022), pp. 1\u20134\n5. P . Singh, R. Kumar, Real-time mask detection using cnns with tensorflow and opencv,\nInternational Journal of Computer Vision and Machine Learning 15, 121 (2023).\n10.1016/j.cvim.2023.08.007\n6. P .G. Nair, Edge device integration for mask detection using opencv and tensorflow, Jour-\nnal of AI and Internet of Things 10, 345 (2023). 10.1007/s00192-023-01999-0\n7. D. Lorenzo, Face mask detection using haar cascade and svm, https://github.com/\ndavidlorenzo47/facemask (2023), accessed: 2023-11-05\n8. I.C. on Face Mask Detection, Face Mask Detection Using CNN Model and Transfer\nLearning, in IEEE Xplore (2023), accessed: 2024-11-05, https://ieeexplore.ieee.\norg/document/10351205\n9. M. Wang, H. Sun, J. Shi, X. Liu, X. Cao, L. Zhang, B. Zhang, Q-YOLO: Efficient\ninference for real-time object detection, in Asian Conference on Pattern Recognition\n(Springer, 2023), pp. 307\u2013321\n10. G. Kaur, R. Sinha, P .K. Tiwari, S.K. Y adav, P . Pandey, R. Raj, A. V ashisth, M. Rakhra,\nFace mask recognition system using cnn model, Neuroscience Informatics 2, 100035\n(2022).\n11. A. Sarraf, M. Azhdari, S. Sarraf et al., A comprehensive review of deep learning ar-\nchitectures for computer vision applications, American Scientific Research Journal for\nEngineering, Technology, and Sciences (ASRJETS) 77, 1 (2021).\n12. H. Huang, C. Wang, B. Dong, Nostalgic adam: Weighting more of the past gradients\nwhen designing the adaptive learning rate, arXiv preprint arXiv:1805.07557 (2018).\n6\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\nFig 5. Model Accuracy chart.\nFig 6. Model Loss chart.\nthe initial training loss but rapidly drops below it after the first epoch. This initial decrease\nsuggests that the model is generalizing well to unseen data. However, fluctuations in the vali-\ndation loss occur in the subsequent epochs, indicating variability in the model\u2019s performance\non the validation dataset.\n4 Conclusion and Future Scope\nIn conclusion, the face mask detection paper marks a significant advancement in utilizing\ndeep learning technologies to enhance public health and safety. By implementing a Convolu-\ntional Neural Network (CNN) architecture with TensorFlow and Keras, the project effectively\nidentifies whether individuals are wearing masks in real-time. This system meets a critical\nneed in public spaces where mask mandates are in effect, facilitating efficient monitoring and\npromoting compliance.\nThe incorporation of data augmentation techniques further ensures that the model gener-\nalizes well, allowing it to adapt to diverse scenarios and varying image qualities for reliable\nperformance. Utilizing cloud resources such as Google Colab and Google Drive boosts the\nproject\u2019s scalability and accessibility. Google Colab provides powerful computational re-\nsources, enabling model training and testing without the limitations of local hardware, while\nGoogle Drive streamlines data storage and retrieval. This cloud-based approach not only\naccelerates the development process but also makes the solution suitable for large-scale de-\nployment in environments like airports, shopping centers, and schools. Future Scope The\nproject can be expanded by integrating real-time video surveillance for monitoring mask com-\npliance in public spaces and enhancing the model to classify different mask types. Deploy-\ning the system on edge devices like smartphones would enable real-time detection without\ncloud dependency. Further improvements could include adopting advanced architectures for\nhigher accuracy, detecting additional safety measures, and implementing a multi-language\nalert system. Additionally, integrating with IoT systems for automated responses, ensuring\ndata privacy, supporting low-bandwidth environments, and creating a user-friendly interface\nfor detailed reporting would enhance the project\u2019s effectiveness and accessibility.\nReferences\n1. A. Soetan, L. Zhang, Mitigating Infectious Disease Transmission with Face Mask De-\ntection Using Machine Learning, in 2023 IEEE Canadian Conference on Electrical and\nComputer Engineering (CCECE) (IEEE, 2023), pp. 423\u2013427\n2. C. Sudthongkhong, B. Intarapasan, T. Wongsheree, K. Thanasuan, B. Pattanapipat,\nP . Suksai, Real-Time Face Mask Detection with Deep Learning for Pandemic Safety,\nin 2023 17th International Conference on Signal-Image Technology & Internet-Based\nSystems (SITIS) (IEEE, 2023), pp. 213\u2013217\n3. A. Kanavos, O. Papadimitriou, K. Al-Hussaeni, M. Maragoudakis, I. Karamitsos, Real-\ntime detection of face mask usage using convolutional neural networks, Computers 13,\n182 (2024).\n4. J. Y edukondalu, T.Y . Singh, D. Sharma, R.S. Singh, L.D. Sharma, Face Mask Detection\nUsing Image Processing and Convolutional Neural Networks, in 2022 IEEE 6th Confer-\nence on Information and Communication Technology (CICT) (IEEE, 2022), pp. 1\u20134\n5. P . Singh, R. Kumar, Real-time mask detection using cnns with tensorflow and opencv,\nInternational Journal of Computer Vision and Machine Learning 15, 121 (2023).\n10.1016/j.cvim.2023.08.007\n6. P .G. Nair, Edge device integration for mask detection using opencv and tensorflow, Jour-\nnal of AI and Internet of Things 10, 345 (2023). 10.1007/s00192-023-01999-0\n7. D. Lorenzo, Face mask detection using haar cascade and svm, https://github.com/\ndavidlorenzo47/facemask (2023), accessed: 2023-11-05\n8. I.C. on Face Mask Detection, Face Mask Detection Using CNN Model and Transfer\nLearning, in IEEE Xplore (2023), accessed: 2024-11-05, https://ieeexplore.ieee.\norg/document/10351205\n9. M. Wang, H. Sun, J. Shi, X. Liu, X. Cao, L. Zhang, B. Zhang, Q-YOLO: Efficient\ninference for real-time object detection, in Asian Conference on Pattern Recognition\n(Springer, 2023), pp. 307\u2013321\n10. G. Kaur, R. Sinha, P .K. Tiwari, S.K. Y adav, P . Pandey, R. Raj, A. V ashisth, M. Rakhra,\nFace mask recognition system using cnn model, Neuroscience Informatics 2, 100035\n(2022).\n11. A. Sarraf, M. Azhdari, S. Sarraf et al., A comprehensive review of deep learning ar-\nchitectures for computer vision applications, American Scientific Research Journal for\nEngineering, Technology, and Sciences (ASRJETS) 77, 1 (2021).\n12. H. Huang, C. Wang, B. Dong, Nostalgic adam: Weighting more of the past gradients\nwhen designing the adaptive learning rate, arXiv preprint arXiv:1805.07557 (2018).\n7\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025\n13. A. Nowrin, S. Afroz, M.S. Rahman, I. Mahmud, Y .Z. Cho, Comprehensive review on\nfacemask detection techniques in the context of covid-19, IEEE access 9, 106839 (2021).\n14. M.A. Ai, A. Shanmugam, S. Muthusamy, C. Viswanathan, H. Panchal, M. Krishnamoor-\nthy, D.S.A. Elminaam, R. Orban, Real-time facemask detection for preventing covid-19\nspread using transfer learning based deep neural network, Electronics 11, 2250 (2022).\n15. R. Shanmugamani, Deep Learning for Computer Vision: Expert techniques to train ad-\nvanced neural networks using TensorFlow and Keras (Packt Publishing Ltd, 2018)\n16. T. Carneiro, R.V .M. Da N\u00f3brega, T. Nepomuceno, G.B. Bian, V .H.C. De Albuquerque,\nP .P . Reboucas Filho, Performance analysis of google colaboratory as a tool for acceler-\nating deep learning applications, Ieee Access 6, 61677 (2018).\n17. I.S.A. MAKBOUL, Ph.D. thesis, Universit\u00e9 Ibn Khaldoun-Tiaret- (2020)\n8\nE3S Web of Conferences 616, 02013 (2025) https://doi.org/10.1051/e3sconf/202561602013\nICREGCSD 2025"}