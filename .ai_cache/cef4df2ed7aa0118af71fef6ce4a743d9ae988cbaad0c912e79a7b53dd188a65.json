{"mtime": 1763038929.5596125, "text": "Here's a concise summary of Unit III\u0000 Introduction to Machine Learning for your viva:\nThis covers the core points you'll need for viva answers on this unit.\n\u2042\nHere are possible viva questions from the topics in your image, including formulas you should\nknow:\nGeneral Questions\nCross Validation\nsummarize this for me for viva\nMachine Learning Overview: Study of algorithms that learn patterns from data to make\npredictions or decisions.\nHandling Datasets: Understanding data types, cleaning data, and preparing datasets for\nmachine learning tasks.\nFeature Sets: Selecting relevant attributes (features) from data that help models learn\neffectively.\nDataset Division: Splitting data into training, validation, and test sets. Use cross-validation\nfor better evaluation of models.\nDimensionality Reduction: Techniques like PCA \u0000Principal Component Analysis), LDA\n\u0000Linear Discriminant Analysis), and ICA \u0000Independent Component Analysis) are used to\nreduce the number of features while retaining essential information.\ntell me all the other questions for viva from these\ntopics like cross validation formulas and\nconfusion matrix formulas\nWhat is machine learning? Give examples.\nHow do you prepare a dataset for machine learning?\nWhat is a feature set? Why is feature selection important?\nWhy do we split data into training, validation, and test sets?\nWhat is cross validation and why is it used?\nExplain k-fold cross validation with steps/formula.\nFormula for accuracy after k-fold split:\nConfusion Matrix\nDimensionality Reduction \u0000PCA, LDA, ICA\u0000\nOther practical/application questions\nThese will help you prepare detailed and formula-based answers for your viva!\nHere are clear, short answers to each of the suggested viva questions:\n1. What is machine learning? Give examples.\n2. How do you prepare a dataset for machine learning?\nWhat are other types of cross validation \u0000Leave-One-Out, Stratified)?\nWhat is a confusion matrix? Draw and explain its components \u0000TP, FP, TN, FN\u0000.\nGive the formulas for:\nAccuracy:\nPrecision:\nRecall \u0000Sensitivity):\nSpecificity:\nF1 Score:\nWhere would you use a confusion matrix in model evaluation?\nWhy is dimensionality reduction important?\nBriefly explain PCA and its main idea.\nWhat is LDA used for?\nDifference between PCA and LDA.\nWhere can ICA be applied in real life?\nHow do you choose the best model for a given dataset?\nWhat problems might occur if you don't split the data properly?\nHow does overfitting relate to dataset division?\nWhat metrics do you use to evaluate a classification model?\ntell me ans for all of these\nMachine learning is a branch of artificial intelligence where computers learn patterns from\ndata to make decisions or predictions, without explicit programming.\nExample: Email spam detection, image recognition, product recommendations.\n3. What is a feature set? Why is feature selection important?\n4. Why do we split data into training, validation, and test sets?\n5. What is cross validation and why is it used?\n6. Explain k-fold cross validation with steps/formula.\n7. What are other types of cross validation \u0000Leave-One-Out, Stratified)?\n8. What is a confusion matrix? Draw and explain its components \u0000TP, FP, TN, FN\u0000.\n9. Give the formulas for:\nClean and preprocess data by removing missing or irrelevant values, normalizing features,\nand encoding categorical variables. Split data into training, validation, and test sets to\nproperly evaluate the model.\nA feature set is the collection of input variables used by the model for learning.\nFeature selection helps improve model accuracy and reduces overfitting by removing\nirrelevant or redundant data.\nTo ensure the model is tested on unseen data, helping to measure its real-world\nperformance and avoid overfitting.\nCross Validation\nCross validation splits data into multiple subsets (folds) and trains the model on each fold\nwhile testing on the remaining fold. It helps assess a model\u02bcs ability to generalize on new\ndata.\nData is divided into k equal folds. The model is trained on k-1 folds and tested on the\nremaining fold. This is done k times, each fold being the test set once.\nAccuracy formula:\nLeave-One-Out: Each sample is used as a single test case, remaining data is training set.\nStratified: Folds are made to preserve the percentage of samples for each class.\nConfusion Matrix\nA confusion matrix is a table showing actual vs predicted classifications:\nTP \u0000True Positive): Correct positive predictions\nTN \u0000True Negative): Correct negative predictions\nFP \u0000False Positive): Incorrect positive predictions\nFN \u0000False Negative): Incorrect negative predictions\n10. Where would you use a confusion matrix in model evaluation?\n11. Why is dimensionality reduction important?\n12. Briefly explain PCA and its main idea.\n13. What is LDA used for?\n14. Difference between PCA and LDA.\n15. Where can ICA be applied in real life?\n16. How do you choose the best model for a given dataset?\n17. What problems might occur if you don\u02bct split the data properly?\n18. How does overfitting relate to dataset division?\nAccuracy:\nPrecision:\nRecall \u0000Sensitivity):\nSpecificity:\nF1 Score:\nTo evaluate classification model performance by showing where the model is making\nmistakes between different classes.\nDimensionality Reduction\nIt reduces the number of input variables, making models faster, reducing overfitting, and\nsometimes improving accuracy by eliminating noise.\nPCA \u0000Principal Component Analysis) transforms original features into new uncorrelated\nvariables (principal components) that capture most variance in the data.\nLDA \u0000Linear Discriminant Analysis) is used for both dimensionality reduction and as a\nclassifier; it aims to maximize the separation between multiple classes.\nPCA finds axes of maximum variance and is unsupervised. LDA finds axes that best\nseparate different classes and is supervised.\nICA \u0000Independent Component Analysis) is used to separate independent sources, e.g.,\nremoving noise from audio signals, separating mixed voices, or medical signal \u0000EEG/ECG)\nprocessing.\nOther practical/application questions\nBy comparing different models using performance metrics (accuracy, precision, recall, F1\nscore, etc.) on the validation set, and selecting the one that works best for your problem.\nModel may overfit to training data and perform poorly on new, unseen data.\n19. What metrics do you use to evaluate a classification model?\nThis should prepare you thoroughly for any viva questions from these topics. If you want\ndetailed examples for any answer, just ask!\nHere are concise definitions for your viva:\nSupervised Learning\nUnsupervised Learning\nKey difference:\nSupervised uses labeled data with known answers, while unsupervised works only with input\ndata to discover hidden patterns.\nHere are concise explanations for each concept:\nNo Free Lunch Theorem\nCurse of Dimensionality\nOverfitting occurs if a model is evaluated only on training data, failing to generalize. Proper\nsplitting ensures unbiased evaluation.\nAccuracy, precision, recall, specificity, F1 score, ROC\u0000AUC.\nwhat is supervised and unsupervised learning\nIn supervised learning, the model is trained on labeled data\u2014that means each input comes\nwith a correct output (target).\nThe model learns to map inputs to outputs based on this data.\nCommon examples: Classification (spam detection), regression (predicting house prices).\nIn unsupervised learning, the model is trained on unlabeled data\u2014there are no explicit\noutputs provided.\nThe goal is to find patterns, groupings, or structure within the data.\nCommon examples: Clustering (customer segmentation), dimensionality reduction \u0000PCA\u0000.\nno free lunge theorem , curse of dimensionality,\nconcept of garbage in garbage out\nThe No Free Lunch Theorem states that there is no single algorithm (or model) that works\nbest for every problem, dataset, or scenario in machine learning.\nIn other words, if an algorithm performs well on one type of problem, it will perform worse on\nsome other type of problem.\nImplication: You must try multiple algorithms and tune them for your specific dataset; there\u02bcs\nno \u201cone-size-fits-all\u201d solution.\nGarbage In, Garbage Out\nThese three concepts are essential for understanding the limitations and best practices in\nmachine learning.\nHere are the types of features in a dataset commonly seen in machine learning:\nThe Curse of Dimensionality refers to problems that arise when working with data having a\nhigh number of features (dimensions).\nAs the number of dimensions increases, data points become sparse, distances become less\nmeaningful, and computational cost rises.\nThis can make machine learning models harder to train, less accurate, and prone to\noverfitting if not handled properly.\nThis concept means that poor quality input data will result in poor quality model predictions\nor outputs.\nIf you feed a machine learning model with incomplete, inaccurate, or irrelevant data, the\nresults will also be unreliable, regardless of the algorithm used.\nEmphasizes the importance of good data preprocessing and cleaning in any data science\npipeline.\ntypes of features in dataset\nNumerical Features:\nRepresent numbers and can be measured (e.g., age, salary, temperature).\nTypes:\nContinuous (any value, e.g., height, price)\nDiscrete (specific counts, e.g., number of children)\nCategorical Features:\nRepresent categories or groups (e.g., gender, color, city).\nTypes:\nNominal (no order, e.g., color: red/blue/green)\nOrdinal (have an order, e.g., size: small/medium/large)\nBoolean/Binary Features:\nOnly two possible values (e.g., yes/no, 0/1, true/false).\nDate & Time Features:\nRepresent time-based data (e.g., date of birth, timestamp). Can be split into year,\nmonth, hour, etc.\nText Features:\nUnderstanding feature types is important for preprocessing and choosing appropriate machine\nlearning algorithms!\nData cleaning is the process of identifying and correcting errors or inconsistencies in a dataset\nto ensure high-quality data for analysis or machine learning.\nKey steps in data cleaning:\nWhy is data cleaning important?\nGood data cleaning is essential before applying any machine learning or statistical analysis!\nOrdinal features are types of categorical features where the categories have a clear,\nmeaningful order or ranking, but the exact difference between categories is not measured.\nExamples:\nKey points about ordinal features:\nConsist of unstructured text (e.g., reviews, comments). Usually processed using\ntechniques like tokenization or bag-of-words.\nDerived Features:\nCreated by combining or transforming existing features (e.g., BMI from weight and\nheight, age from birth date).\nwhat is data cleaning\nRemoving duplicates: Delete identical rows that appear more than once.\nHandling missing values: Fill in, estimate, or remove data points with missing entries.\nCorrecting errors: Fix incorrect or misformatted values (e.g., typos, wrong units).\nFiltering outliers: Detect and handle values that are unusually high or low compared to the\nrest of the data.\nStandardizing formats: Make sure all data follows a consistent format (e.g., DD/MM/YYYY\nfor dates).\nRemoving irrelevant data: Delete columns or rows that do not contribute to the analysis.\nClean data leads to more accurate, reliable, and interpretable models.\nIt avoids the problem of \u201cgarbage in, garbage out\u201d (bad data causes bad results).\nwhat is ordinal features\nSize \u0000Small, Medium, Large)\nEducation level \u0000High School, Bachelor\u02bcs, Master\u02bcs, PhD\u0000\nRatings \u0000Poor, Average, Good, Excellent)\nGrade \u0000A, B, C, D, F\u0000\nOrdinal features help machine learning models recognize ranking or progression in data, for\nexample, predicting satisfaction levels or performance tiers.\nFeature scaling is the process of transforming the values of numerical features in a dataset to a\ncommon scale, without distorting differences in the ranges of values.\nWhy is it needed?\nCommon methods of feature scaling:\nSummary:\nFeature scaling is a key preprocessing step to improve the performance and reliability of\nmachine learning models.\n\u2042\nOrdinal encoding is a method used to convert ordinal categorical features (features with\nordered categories) into numerical values based on their order or rank.\nHow it works:\nThe order matters (there\u02bcs a ranking).\nThe distance between categories is not defined (difference between \"Medium\" and \"Large\"\nisn't exactly equal to \"Small\" and \"Medium\").\nThey often require special treatment during encoding, like assigning ordered numbers (e.g.,\n1, 2, 3) or using ordinal encoding.\nwhat is features scaling\nMany machine learning algorithms (like k-nearest neighbors, support vector machines,\nneural networks) work better or converge faster if features are on similar scales.\nPrevents features with large values from dominating those with small values.\nMin-Max Scaling \u0000Normalization): Scales values to a range, usually.\u00002\u0000\nStandardization \u0000Z-score Scaling): Scales values so that they have mean 0 and standard\ndeviation 1.\nwhere $ \\mu $ is mean and $ \\sigma $ is standard deviation.\nwhat is ordinal encoding\nEach category is assigned an integer value that represents its order.\nFor example, for the feature \"Size\" with categories \u0000Small, Medium, Large]:\nSmall \u2192  1\nWhy use ordinal encoding?\nImportant note:\nOrdinal encoding should only be applied to ordinal features (with a natural order). Using it for\nnominal features (where no order exists) can mislead the model.\nSummary:\nOrdinal encoding transforms ordered categories into integers to preserve their ranking for\nmachine learning models.\nHere are the main types of encoding used for categorical features in machine learning:\n1. Ordinal Encoding\n2. One-Hot Encoding\n3. Label Encoding\n4. Binary Encoding\n5. Target/Mean Encoding\n6. Frequency Encoding\nMedium \u2192  2\nLarge \u2192  3\nIt allows machine learning algorithms to recognize and use the order of categories.\nEspecially useful for algorithms that can leverage rankings, such as tree-based models.\ntypes of encoding\nAssigns integers based on category order.\nUse for ordinal features (e.g., \u0000Low=0, Medium=1, High=2\u0000\u0000.\nCreates a new binary column for each category; each row gets a 1 where the category is\npresent and 0 elsewhere.\nUse for nominal features (no order), e.g., \u0000Red, Blue, Green] becomes three columns.\nAssigns a unique integer to each category.\nLike ordinal encoding but may be misused if there is no order.\nConverts categories to binary digits and splits each digit into a separate column.\nHelps reduce the number of columns compared to one-hot encoding for features with many\ncategories.\nReplace each category with the mean of the target variable for that category.\nOften used in supervised tasks, sensitive to data leakage if not applied carefully.\nReplace each category with its frequency (how many times it appears).\nSummary Table:\nEncoding Type When to Use Output Format\nOrdinal Encoding Ordinal Features (with order) Single integer per category\nOne-Hot Encoding Nominal Features (no order) Binary columns per category\nLabel Encoding Any categorical (rarely prefer) Single integer per category\nBinary Encoding Categories with many unique values Multiple binary columns\nTarget Encoding Categorical with target prediction Numeric mean values\nFrequency Encoding Any categorical Numeric frequency values\nChoosing the right encoding type helps your model use categorical data effectively!\nHere are the common types of cross-validation techniques in machine learning:\n1. Hold-Out Cross Validation\n2. k-Fold Cross Validation\n3. Stratified k-Fold Cross Validation\n4. Leave-One-Out Cross Validation \u0000LOOCV\u0000\n5. Leave-P\u0000Out Cross Validation\nexplain types of cross validation techniques\nSplit the dataset into two parts: training set and testing set (e.g., 80% train, 20% test).\nSimple, but results may vary depending on the split.\nDataset is divided into  equal-sized folds.\nTrain the model on  folds and test on the remaining fold. Repeat  times, each fold\nserving as test set once.\nAverage performance is reported.\nSimilar to k-fold, but ensures each fold has the same proportion of target classes as the\nwhole dataset.\nUseful for imbalanced datasets (classification problems).\nA special case of k-fold where  (number of samples).\nEach iteration uses one data point as the test set, others as training set.\nComputationally expensive for large datasets.\nSimilar to LOOCV, but  samples are left out as the test set for each iteration.\nUsed for small datasets or specific scenarios.\n6. Group k-Fold Cross Validation\n7. Time Series (or Rolling/Walk-forward) Cross Validation\nSummary Table:\nTechnique When to Use\nHold-Out Quick, basic splitting\nk-Fold General evaluation, all datasets\nStratified k-Fold Imbalanced classification problems\nLeave-One-Out \u0000LOOCV\u0000 Small datasets, thorough evaluation\nLeave-P\u0000Out Very small datasets or research\nGroup k-Fold Grouped/related samples\nTime Series/Walk-forward Sequential/time series datasets\nThese techniques help to properly evaluate model performance and ensure it generalizes well to\nunseen data.\nOversampling and undersampling are techniques used to handle class imbalance in datasets,\ncommonly found in classification problems.\nOversampling\nEnsures that the same group (such as data from the same user) do not appear in both\ntraining and testing sets.\nUsed when samples are related within groups.\nFor sequential or time series data.\nTraining is always on past data, and validation on future data\u2014a rolling or expanding\nwindow is used.\nPrevents data leakage by respecting chronological order.\nwhat is oversampling and under sampling\nIncreases the number of samples in the minority class to balance it with the majority class.\nCommon methods:\nRandom Oversampling: Duplicate examples from the minority class.\nSMOTE \u0000Synthetic Minority Over-sampling Technique): Generates synthetic data\npoints for the minority class using interpolation.\nAdvantage: Helps models learn minority class better.\nDisadvantage: Can lead to overfitting if too many duplicates are added.\nUndersampling\nSummary Table:\nTechnique Goal Method\nOversampling Increase minority Duplicate/synthetic samples\nUndersampling Reduce majority Remove/reduce samples\nBalancing the dataset using these methods ensures better and fairer model training, especially\nwhen one class is much less frequent than the others.\nRegression is a type of supervised machine learning technique used to predict a continuous\noutput (numerical value) from input features.\nKey points:\nCommon regression algorithms:\nExample use cases:\nSummary:\nRegression helps estimate real values by finding patterns and relationships in data.\nReduces the number of samples in the majority class to balance with the minority class.\nCommon methods:\nRandom Undersampling: Remove random samples from the majority class.\nCluster Centroids: Replace the majority class data points with cluster centroids to\nreduce information loss.\nAdvantage: Reduces training time and class imbalance.\nDisadvantage: May discard useful data, causing loss of information.\nwhat is regression\nThe goal is to learn the relationship between one or more independent variables\n(inputs/features) and a dependent variable (output/target).\nThe output variable is continuous (e.g., predicting house prices, temperature, stock values).\nLinear Regression: Predicts output as a linear combination of input features.\nFormula: $ y = mx + b $ (for single feature)\nPolynomial Regression: Uses polynomial functions to fit the data.\nRidge/Lasso Regression: Regularized forms of linear regression to prevent overfitting.\nLogistic Regression: Used for classification, not regression (despite its name).\nPredicting exam scores based on study hours.\nForecasting sales, demand, temperature, etc.\nHere's the difference between feature selection and data cleaning:\nFeature Selection\nData Cleaning\nAspect Feature Selection Data Cleaning\nGoal Select most useful features Improve overall data quality\nAffects Columns (features) All parts of dataset\nCommon steps Remove irrelevant/redundant columns Fix missing, duplicate, wrong values\nWhen used After cleaning, before modeling Early in preprocessing\nSummary:\nFeature selection is about choosing \"what\" variables to use; data cleaning is about making sure\nall data is correct and usable. Both are essential in preparing data for machine learning but serve\ndifferent roles.\nData augmentation is a technique used to artificially increase the size and diversity of a dataset\nby creating modified versions of existing data samples.\nMain purpose:\ndifference between features selection and data\ncleaning\nPurpose: Choose the most relevant and useful features (columns) from the dataset for model\nbuilding.\nFocus: Identifies features that contribute most towards the target variable, removing\nredundant or irrelevant features.\nMethods: Statistical tests, correlation analysis, wrapper and embedded methods, feature\nimportance from models.\nExample: Removing a column like \"ID\" or including only columns that help make accurate\npredictions.\nPurpose: Fix errors or inconsistencies in the entire dataset to ensure high data quality.\nFocus: Handles missing values, removes duplicates, corrects typos, filters out outliers, and\nstandardizes formats.\nMethods: Imputation, duplicate removal, outlier detection, data type correction.\nExample: Filling missing values in \"age\" column, fixing date formats, deleting duplicate rows.\nwhat is data augmentation\nCommon methods:\nBenefits:\nExample:\nSummary:\nData augmentation creates new training samples by modifying existing ones, making models\nmore accurate and better at handling real-world variations.\nGeneralization in machine learning refers to a model's ability to perform well on new, unseen\ndata (data that was not used for training).\nKey points:\nHow to assess generalization:\nSummary:\nGeneralization is the primary goal in machine learning: building models that work reliably on real-\nHelps improve model performance, generalization, and robustness, especially when data is\nlimited.\nImages:\nFlipping, rotating, cropping, zooming, adding noise, changing brightness/contrast.\nText:\nSynonym replacement, rephrasing, adding or removing words.\nTabular data:\nAdding noise, generating synthetic samples (e.g., using SMOTE\u0000, combining samples.\nReduces overfitting by providing more varied training data.\nAllows deep learning models (like those for computer vision) to work with limited real\nsamples.\nIn handwriting recognition, you can rotate, stretch, or blur scanned images of digits to\ncreate more training data.\nwhat is generalization\nA model that generalizes well can make accurate predictions on data outside of its training\nset.\nOverfitting means the model only performs well on the training data but poorly on new data\n\u2014poor generalization.\nUnderfitting means the model isn't even capturing patterns in the training data\u2014also poor\ngeneralization.\nSplit data into training and test sets; test set accuracy shows how well the model\ngeneralizes.\nUse cross-validation to check performance on multiple unseen portions of data.\nworld, previously unseen data, not just the data used for training.\nBox Plot\nEigenvalues\nSummary:\nwhat is box plot and eigen values\nA box plot (or box-and-whisker plot) is a graphical representation of the distribution of a\ndataset.\nIt shows the median, quartiles \u0000Q1 and Q3\u0000, minimum and maximum values, and possible\noutliers.\nVisual elements:\nBox: Contains data between the first \u0000Q1) and third quartile \u0000Q3\u0000.\nLine inside the box: Shows the median \u0000Q2\u0000.\nWhiskers: Extend to the minimum and maximum values within 1.5\u0000IQR (interquartile\nrange).\nPoints outside whiskers: Represent outliers.\nBox plots are useful for understanding data spread, symmetry, and spotting outliers.\nEigenvalues are scalars used in linear algebra, particularly in Principal Component Analysis\n\u0000PCA\u0000, dimensionality reduction, and system analysis.\nFor a square matrix , an eigenvalue  satisfies the equation:\nHere,  is the eigenvector, and  is the eigenvalue.\nEigenvalues help determine the amount of variation captured along each principal axis in\nPCA; larger eigenvalues mean directions with more data variance.\nBox plot: A graph showing the center, spread, and outliers of data.\nEigenvalues: Numbers that indicate how much variance or \"strength\" is present along each\ndirection in a transformation or matrix, useful in feature extraction and dimensionality\nreduction.\n\u0000\u0000\u0000image.jpeg\n\u0000\u0000\u0000image.jpeg"}