{"mtime": 1763055002.1219459, "text": "Viva Questions and Answers \nReal-Time Mask Detection Project \n \nProject Overview and Basics \nQ: What is the objective of your real-time mask detection project? \nA: The project aims to detect whether people are wearing face masks in real-time using a computer \nvision model to help public health safety. \nQ: What datasets did you use? \nA: We used a dataset of around 9,000 images labeled as with_mask and without_mask to train the \nmodel. \n \nModel and Technical Questions \nQ: What model architecture did you use for mask detection? \nA: We used a MobileNetV2-based CNN model for feature extraction combined with a custom \nclassifier trained on the mask dataset. \nQ: Why did you choose MobileNetV2? \nA: MobileNetV2 offers a good balance of lightweight architecture and accuracy, enabling real-time \nperformance on edge devices. \nQ: Can you explain your model training process? \nA: We preprocessed images using augmentation, trained the MobileNetV2-based classifier with \nAdam optimizer, binary cross-entropy loss for around 20 epochs, and evaluated with accuracy and \nloss metrics. \nQ: Why is k-NN not suitable for this task despite the dataset size? \nA: k-NN is computationally expensive at inference time, making real-time detection impractical \ncompared to CNN-based models. \n \nCode and Implementation \nQ: What are the key steps in your detection pipeline? \nA: The pipeline detects faces using OpenCV's DNN face detector, extracts face ROI, preprocesses it, \nand passes it to the mask classifier to predict mask status. \nQ: How do you handle multiple faces in the camera frame? \nA: We batch process all detected face ROIs for mask prediction in a single pass to improve speed and \naccuracy. \nQ: How does your Tkinter GUI function? \nA: The GUI captures video feed, displays bounding boxes and labels for each detected face, and \nshows real-time plots of mask compliance statistics. \n \nGraphs and Results \nQ: What graphs did you generate from your training and detection? \nA: We plotted training/validation accuracy and loss curves to show model learning progress, and \nreal-time bar plots of mask-wearer counts. \nQ: What do these graphs indicate about your model's performance? \nA: Consistent improvement in accuracy and decreasing loss during training show good model \nconvergence; real-time stats reflect detection effectiveness. \n \nChallenges and Improvements \nQ: What were the challenges faced? \nA: Handling varying lighting conditions, occlusions, and ensuring model speed without compromising \naccuracy. \nQ: How did you improve detection speed? \nA: Batch predictions for multiple faces and using a lightweight MobileNetV2 backbone made \ndetection faster. \nQ: What future enhancements do you suggest? \nA: Adding temporal smoothing for prediction stability, supporting more mask categories, and \ndeploying on mobile devices. \n \nAdditional Viva Questions \nQ: Why is real-time mask detection necessary in public health? \nA: It helps monitor and enforce mask-wearing compliance to limit the spread of airborne viruses. \nQ: What libraries did you use in your code? \nA: Mainly OpenCV for face detection, TensorFlow/Keras for the CNN model, and Tkinter for the GUI. \nQ: How did you handle data imbalance if any? \nA: Through data augmentation techniques like rotation, flips, and zoom to increase minority class \nsamples. \nQ: Can this project be deployed on mobile or embedded devices? \nA: Yes, due to the lightweight model architecture, it can be ported using TensorFlow Lite or similar \nframeworks for edge deployment. "}